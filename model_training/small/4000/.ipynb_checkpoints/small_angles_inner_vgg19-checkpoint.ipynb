{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorflow\n",
    "import tensorflow as tf\n",
    "# Below command is to avoid the known bug which prevents computation on some GPU devices\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# Load preprocessing tools\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from PIL import Image\n",
    "# Load model building blocks\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Load pre-trained model library\n",
    "from tensorflow.keras import applications\n",
    "# Load miscelaneous libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'image_data', 'small', '4000', 'train')\n",
    "val_image_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'image_data', 'small', '4000', 'val')\n",
    "train_labels_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'labels', 'small', '4000', 'train')\n",
    "val_labels_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'labels', 'small', '4000', 'val')\n",
    "load_models_path = os.path.join('/home', 'renat_sergazinov', 'python-git-workspace', \n",
    "                               'PhotoForceReconML', 'models')\n",
    "save_models_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'models', 'small', '4000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the directory. The data are the images of particles split into subdirectories based on the number of forces acting on the particle. The labels should be loaded from a separate directory. Each label corresponds to two particles. \n",
    "\n",
    "The size of all images is adjusted so that all images are 128*128 using nearest neighbor interpolation. Validation split is performed: 20% is set aside for validation. Additionally images are blurred using Gaussian blur with kernel radius = 1.The pixel values are scaled using 1/255 to be in the interval [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sorter of image names in order by image number (default is alphanumric)\n",
    "def sorter(item):\n",
    "    # Since highest marks first, least error = most marks\n",
    "    radius = float(item[1 : item.find('_')])\n",
    "    num_img = int(item[item.find('g') + 1 : item.find('j') - 1])\n",
    "    return (radius, num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and validation sets\n",
    "\n",
    "X_train, X_val = {}, {}\n",
    "y_train, y_val = {}, {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    X_path_train = os.path.join(train_image_path, str(i))\n",
    "    X_path_val = os.path.join(val_image_path, str(i))\n",
    "    X_train[i] = [os.path.join(X_path_train, name) for name in sorted(os.listdir(X_path_train), key = sorter)]\n",
    "    X_val[i] = [os.path.join(X_path_val, name) for name in sorted(os.listdir(X_path_val), key = sorter)]\n",
    "    y_train[i] = np.load(os.path.join(train_labels_path, str(i), 'angles_inner.npy'))\n",
    "    y_val[i] = np.load(os.path.join(val_labels_path, str(i), 'angles_inner.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for data generation\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_image_paths = None, labels = None,  \n",
    "                 batch_size = 32, dim = None, n_channels = 3, rescale = 1, \n",
    "                 shuffle=True, save_dir = None, preprocessing_func = None):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_image_paths = list_image_paths\n",
    "        self.n_channels = n_channels\n",
    "        self.rescale = rescale\n",
    "        self.shuffle = shuffle\n",
    "        self.save_dir = save_dir\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indices)\n",
    "        \n",
    "        if self.save_dir is not None:\n",
    "            for i in range(X.shape[0]):\n",
    "                path = os.path.join(self.save_dir, 'img' + str(i) + '.jpg')\n",
    "                plt.imsave(path, np.asarray(X[i, ]), vmin = 0, vmax = 1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indices = np.arange(len(self.list_image_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, indices):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        \n",
    "        # Initialisation\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        list_image_paths_batch = [self.list_image_paths[k] for k in indices]\n",
    "        \n",
    "        # Get labels\n",
    "        y = np.array([self.labels[k, :] for k in indices])\n",
    "        \n",
    "        # Generate data\n",
    "        for i, image_path in enumerate(list_image_paths_batch):\n",
    "            # Load image and transform\n",
    "            image = Image.open(os.path.join(image_path))\n",
    "            if self.dim is not None:\n",
    "                image = image.resize(self.dim, resample = Image.NEAREST)\n",
    "            image = np.array(image)[:, :, :self.n_channels]\n",
    "            image = image * self.rescale\n",
    "            if self.preprocessing_func is not None:\n",
    "                image = self.preprocessing_func(image)\n",
    "            # Store sample\n",
    "            X[i,] = image\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian blur class\n",
    "class GaussBlur:\n",
    "    def __init__(self, radius):\n",
    "        self.radius = radius\n",
    "    def blur(self, image):\n",
    "        return gaussian_filter(image, sigma = self.radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data generators\n",
    "gaussblur = GaussBlur(1)\n",
    "params = {'batch_size': 32, \n",
    "          'dim': (128, 128), \n",
    "          'n_channels': 3, \n",
    "          'rescale': 1 / 255, \n",
    "          'shuffle': True, \n",
    "          'save_dir': None,\n",
    "          'preprocessing_func': gaussblur.blur\n",
    "          }\n",
    "\n",
    "training_generator = {}\n",
    "validation_generator = {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    training_generator[i] = DataGenerator(X_train[i], y_train[i], **params)\n",
    "    validation_generator[i] = DataGenerator(X_val[i], y_val[i], **params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19 Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks is defined and compiled in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ai = dict()                         \n",
    "for k in range(5):\n",
    "     i = k + 2\n",
    "     models_ai[i] = load_model(os.path.join(load_models_path, 'vgg19_angles_inner_'+str(i)+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 28,416,066\n",
      "Trainable params: 28,416,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 28,417,091\n",
      "Trainable params: 28,417,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 28,418,116\n",
      "Trainable params: 28,418,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 28,419,141\n",
      "Trainable params: 28,419,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 28,420,166\n",
      "Trainable params: 28,420,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    models_ai[i].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    i = 2 + k\n",
    "    models_ai[i].compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-7),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for  2  angles\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1547 - mean_absolute_error: 0.1547\n",
      "Epoch 00001: val_loss improved from inf to 0.06315, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.1547 - mean_absolute_error: 0.1547 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1496 - mean_absolute_error: 0.1496\n",
      "Epoch 00002: val_loss improved from 0.06315 to 0.05283, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1496 - mean_absolute_error: 0.1496 - val_loss: 0.0528 - val_mean_absolute_error: 0.0528\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1469 - mean_absolute_error: 0.1469\n",
      "Epoch 00003: val_loss improved from 0.05283 to 0.04255, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.1469 - mean_absolute_error: 0.1469 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1453 - mean_absolute_error: 0.1453\n",
      "Epoch 00004: val_loss improved from 0.04255 to 0.03660, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1453 - mean_absolute_error: 0.1453 - val_loss: 0.0366 - val_mean_absolute_error: 0.0366\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1428 - mean_absolute_error: 0.1428\n",
      "Epoch 00005: val_loss did not improve from 0.03660\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1428 - mean_absolute_error: 0.1428 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1402 - mean_absolute_error: 0.1402\n",
      "Epoch 00006: val_loss improved from 0.03660 to 0.03580, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.1407\n",
      "Epoch 00007: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.0481 - val_mean_absolute_error: 0.0481\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1402 - mean_absolute_error: 0.1402\n",
      "Epoch 00008: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.0468 - val_mean_absolute_error: 0.0468\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1435 - mean_absolute_error: 0.1435\n",
      "Epoch 00009: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1435 - mean_absolute_error: 0.1435 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1402 - mean_absolute_error: 0.1402\n",
      "Epoch 00010: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1373 - mean_absolute_error: 0.1373\n",
      "Epoch 00011: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1398 - mean_absolute_error: 0.1398\n",
      "Epoch 00012: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.1398 - mean_absolute_error: 0.1398 - val_loss: 0.0548 - val_mean_absolute_error: 0.0548\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1405 - mean_absolute_error: 0.1405\n",
      "Epoch 00013: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1405 - mean_absolute_error: 0.1405 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1403 - mean_absolute_error: 0.1403\n",
      "Epoch 00014: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1403 - mean_absolute_error: 0.1403 - val_loss: 0.0379 - val_mean_absolute_error: 0.0379\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1404 - mean_absolute_error: 0.1404\n",
      "Epoch 00015: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.0415 - val_mean_absolute_error: 0.0415\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00016: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0646 - val_mean_absolute_error: 0.0646\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1391 - mean_absolute_error: 0.1391\n",
      "Epoch 00017: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1391 - mean_absolute_error: 0.1391 - val_loss: 0.0515 - val_mean_absolute_error: 0.0515\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1424 - mean_absolute_error: 0.1424\n",
      "Epoch 00018: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1424 - mean_absolute_error: 0.1424 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.1407\n",
      "Epoch 00019: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.0454 - val_mean_absolute_error: 0.0454\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00020: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0490 - val_mean_absolute_error: 0.0490\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1373 - mean_absolute_error: 0.1373\n",
      "Epoch 00021: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.0474 - val_mean_absolute_error: 0.0474\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00022: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1396 - mean_absolute_error: 0.1396\n",
      "Epoch 00023: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1402 - mean_absolute_error: 0.1402\n",
      "Epoch 00024: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1377 - mean_absolute_error: 0.1377\n",
      "Epoch 00025: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00026: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0505 - val_mean_absolute_error: 0.0505\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1356 - mean_absolute_error: 0.1356\n",
      "Epoch 00027: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1386 - mean_absolute_error: 0.1386\n",
      "Epoch 00028: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1386 - mean_absolute_error: 0.1386 - val_loss: 0.0490 - val_mean_absolute_error: 0.0490\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1387 - mean_absolute_error: 0.1387\n",
      "Epoch 00029: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.0432 - val_mean_absolute_error: 0.0432\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1397 - mean_absolute_error: 0.1397\n",
      "Epoch 00030: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1397 - mean_absolute_error: 0.1397 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1392 - mean_absolute_error: 0.1392\n",
      "Epoch 00031: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1392 - mean_absolute_error: 0.1392 - val_loss: 0.0441 - val_mean_absolute_error: 0.0441\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.1407\n",
      "Epoch 00032: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1388 - mean_absolute_error: 0.1388\n",
      "Epoch 00033: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1388 - mean_absolute_error: 0.1388 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00034: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0458 - val_mean_absolute_error: 0.0458\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 00035: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1389 - mean_absolute_error: 0.1389\n",
      "Epoch 00036: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1389 - mean_absolute_error: 0.1389 - val_loss: 0.0668 - val_mean_absolute_error: 0.0668\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.1359\n",
      "Epoch 00037: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00038: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00039: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0449 - val_mean_absolute_error: 0.0449\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1364 - mean_absolute_error: 0.1364\n",
      "Epoch 00040: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1364 - mean_absolute_error: 0.1364 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1399 - mean_absolute_error: 0.1399\n",
      "Epoch 00041: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1399 - mean_absolute_error: 0.1399 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1411 - mean_absolute_error: 0.1411\n",
      "Epoch 00042: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1411 - mean_absolute_error: 0.1411 - val_loss: 0.0458 - val_mean_absolute_error: 0.0458\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1401 - mean_absolute_error: 0.1401\n",
      "Epoch 00043: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1401 - mean_absolute_error: 0.1401 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1371 - mean_absolute_error: 0.1371\n",
      "Epoch 00044: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1371 - mean_absolute_error: 0.1371 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1368 - mean_absolute_error: 0.1368\n",
      "Epoch 00045: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1368 - mean_absolute_error: 0.1368 - val_loss: 0.0476 - val_mean_absolute_error: 0.0476\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1418 - mean_absolute_error: 0.1418\n",
      "Epoch 00046: val_loss did not improve from 0.03580\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00047: val_loss improved from 0.03580 to 0.03532, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0353 - val_mean_absolute_error: 0.0353\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00048: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00049: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0538 - val_mean_absolute_error: 0.0538\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00050: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0593 - val_mean_absolute_error: 0.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1396 - mean_absolute_error: 0.1396\n",
      "Epoch 00051: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1416 - mean_absolute_error: 0.1416\n",
      "Epoch 00052: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1416 - mean_absolute_error: 0.1416 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 00053: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.1372\n",
      "Epoch 00054: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.1342\n",
      "Epoch 00055: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1364 - mean_absolute_error: 0.1364\n",
      "Epoch 00056: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1364 - mean_absolute_error: 0.1364 - val_loss: 0.0693 - val_mean_absolute_error: 0.0693\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1379 - mean_absolute_error: 0.1379\n",
      "Epoch 00057: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1379 - mean_absolute_error: 0.1379 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00058: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0492 - val_mean_absolute_error: 0.0492\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.1359\n",
      "Epoch 00059: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1378 - mean_absolute_error: 0.1378\n",
      "Epoch 00060: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00061: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1395 - mean_absolute_error: 0.1395\n",
      "Epoch 00062: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1395 - mean_absolute_error: 0.1395 - val_loss: 0.0405 - val_mean_absolute_error: 0.0405\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1350 - mean_absolute_error: 0.1350\n",
      "Epoch 00063: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1350 - mean_absolute_error: 0.1350 - val_loss: 0.0480 - val_mean_absolute_error: 0.0480\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 00064: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1377 - mean_absolute_error: 0.1377\n",
      "Epoch 00065: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1390 - mean_absolute_error: 0.1390\n",
      "Epoch 00066: val_loss did not improve from 0.03532\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.0414 - val_mean_absolute_error: 0.0414\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1354\n",
      "Epoch 00067: val_loss improved from 0.03532 to 0.03383, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.0338 - val_mean_absolute_error: 0.0338\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1336 - mean_absolute_error: 0.1336\n",
      "Epoch 00068: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.0560 - val_mean_absolute_error: 0.0560\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00069: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0477 - val_mean_absolute_error: 0.0477\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 00070: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1382 - mean_absolute_error: 0.1382\n",
      "Epoch 00071: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1382 - mean_absolute_error: 0.1382 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1382 - mean_absolute_error: 0.1382\n",
      "Epoch 00072: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1382 - mean_absolute_error: 0.1382 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1337 - mean_absolute_error: 0.1337\n",
      "Epoch 00073: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00074: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0474 - val_mean_absolute_error: 0.0474\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00075: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0430 - val_mean_absolute_error: 0.0430\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.1366\n",
      "Epoch 00076: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1403 - mean_absolute_error: 0.1403\n",
      "Epoch 00077: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1403 - mean_absolute_error: 0.1403 - val_loss: 0.0524 - val_mean_absolute_error: 0.0524\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1352 - mean_absolute_error: 0.1352\n",
      "Epoch 00078: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 00079: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1395 - mean_absolute_error: 0.1395\n",
      "Epoch 00080: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1395 - mean_absolute_error: 0.1395 - val_loss: 0.0418 - val_mean_absolute_error: 0.0418\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1352 - mean_absolute_error: 0.1352\n",
      "Epoch 00081: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1369 - mean_absolute_error: 0.1369\n",
      "Epoch 00082: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1369 - mean_absolute_error: 0.1369 - val_loss: 0.0407 - val_mean_absolute_error: 0.0407\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1418 - mean_absolute_error: 0.1418\n",
      "Epoch 00083: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.0395 - val_mean_absolute_error: 0.0395\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - mean_absolute_error: 0.1365\n",
      "Epoch 00084: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.0666 - val_mean_absolute_error: 0.0666\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.1353\n",
      "Epoch 00085: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.0512 - val_mean_absolute_error: 0.0512\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1363 - mean_absolute_error: 0.1363\n",
      "Epoch 00086: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.0575 - val_mean_absolute_error: 0.0575\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.1372\n",
      "Epoch 00087: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1330 - mean_absolute_error: 0.1330\n",
      "Epoch 00088: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.0431 - val_mean_absolute_error: 0.0431\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00089: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1379 - mean_absolute_error: 0.1379\n",
      "Epoch 00090: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1379 - mean_absolute_error: 0.1379 - val_loss: 0.0493 - val_mean_absolute_error: 0.0493\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1410 - mean_absolute_error: 0.1410\n",
      "Epoch 00091: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.0384 - val_mean_absolute_error: 0.0384\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.1372\n",
      "Epoch 00092: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.0374 - val_mean_absolute_error: 0.0374\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1378 - mean_absolute_error: 0.1378\n",
      "Epoch 00093: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.0463 - val_mean_absolute_error: 0.0463\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1356 - mean_absolute_error: 0.1356\n",
      "Epoch 00094: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.0367 - val_mean_absolute_error: 0.0367\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.1353\n",
      "Epoch 00095: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.0388 - val_mean_absolute_error: 0.0388\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1395 - mean_absolute_error: 0.1395\n",
      "Epoch 00096: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1395 - mean_absolute_error: 0.1395 - val_loss: 0.0453 - val_mean_absolute_error: 0.0453\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00097: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0489 - val_mean_absolute_error: 0.0489\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00098: val_loss did not improve from 0.03383\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.1359\n",
      "Epoch 00099: val_loss improved from 0.03383 to 0.02907, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1374 - mean_absolute_error: 0.1374\n",
      "Epoch 00100: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1374 - mean_absolute_error: 0.1374 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00101: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1370 - mean_absolute_error: 0.1370\n",
      "Epoch 00102: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.0445 - val_mean_absolute_error: 0.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1345 - mean_absolute_error: 0.1345\n",
      "Epoch 00103: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1345 - mean_absolute_error: 0.1345 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.1353\n",
      "Epoch 00104: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.0689 - val_mean_absolute_error: 0.0689\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1377 - mean_absolute_error: 0.1377\n",
      "Epoch 00105: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.0498 - val_mean_absolute_error: 0.0498\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1383 - mean_absolute_error: 0.1383\n",
      "Epoch 00106: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1383 - mean_absolute_error: 0.1383 - val_loss: 0.0411 - val_mean_absolute_error: 0.0411\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1364 - mean_absolute_error: 0.1364\n",
      "Epoch 00107: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1364 - mean_absolute_error: 0.1364 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1394 - mean_absolute_error: 0.1394\n",
      "Epoch 00108: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1394 - mean_absolute_error: 0.1394 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1405 - mean_absolute_error: 0.1405\n",
      "Epoch 00109: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1405 - mean_absolute_error: 0.1405 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1378 - mean_absolute_error: 0.1378\n",
      "Epoch 00110: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1346 - mean_absolute_error: 0.1346\n",
      "Epoch 00111: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1346 - mean_absolute_error: 0.1346 - val_loss: 0.0400 - val_mean_absolute_error: 0.0400\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00112: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.1366\n",
      "Epoch 00113: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.0454 - val_mean_absolute_error: 0.0454\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00114: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0328 - val_mean_absolute_error: 0.0328\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1373 - mean_absolute_error: 0.1373\n",
      "Epoch 00115: val_loss did not improve from 0.02907\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - mean_absolute_error: 0.1365\n",
      "Epoch 00116: val_loss improved from 0.02907 to 0.02620, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_2.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1323 - mean_absolute_error: 0.1323\n",
      "Epoch 00117: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1331 - mean_absolute_error: 0.1331\n",
      "Epoch 00118: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1331 - mean_absolute_error: 0.1331 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1393 - mean_absolute_error: 0.1393\n",
      "Epoch 00119: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.0659 - val_mean_absolute_error: 0.0659\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1369 - mean_absolute_error: 0.1369\n",
      "Epoch 00120: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1369 - mean_absolute_error: 0.1369 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00121: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0541 - val_mean_absolute_error: 0.0541\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.1366\n",
      "Epoch 00122: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1346 - mean_absolute_error: 0.1346\n",
      "Epoch 00123: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1346 - mean_absolute_error: 0.1346 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00124: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1341 - mean_absolute_error: 0.1341\n",
      "Epoch 00125: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1341 - mean_absolute_error: 0.1341 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00126: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00127: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0459 - val_mean_absolute_error: 0.0459\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1368 - mean_absolute_error: 0.1368\n",
      "Epoch 00128: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1368 - mean_absolute_error: 0.1368 - val_loss: 0.0417 - val_mean_absolute_error: 0.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1416 - mean_absolute_error: 0.1416\n",
      "Epoch 00129: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1416 - mean_absolute_error: 0.1416 - val_loss: 0.0317 - val_mean_absolute_error: 0.0317\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 00130: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.0466 - val_mean_absolute_error: 0.0466\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00131: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0480 - val_mean_absolute_error: 0.0480\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.1407\n",
      "Epoch 00132: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1339 - mean_absolute_error: 0.1339\n",
      "Epoch 00133: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1402 - mean_absolute_error: 0.1402\n",
      "Epoch 00134: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1379 - mean_absolute_error: 0.1379\n",
      "Epoch 00135: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1379 - mean_absolute_error: 0.1379 - val_loss: 0.0370 - val_mean_absolute_error: 0.0370\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00136: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0368 - val_mean_absolute_error: 0.0368\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1390 - mean_absolute_error: 0.1390\n",
      "Epoch 00137: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.0390 - val_mean_absolute_error: 0.0390\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00138: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0439 - val_mean_absolute_error: 0.0439\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1375 - mean_absolute_error: 0.1375\n",
      "Epoch 00139: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1375 - mean_absolute_error: 0.1375 - val_loss: 0.0405 - val_mean_absolute_error: 0.0405\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1355 - mean_absolute_error: 0.1355\n",
      "Epoch 00140: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00141: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00142: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00143: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1376 - mean_absolute_error: 0.1376\n",
      "Epoch 00144: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1376 - mean_absolute_error: 0.1376 - val_loss: 0.0410 - val_mean_absolute_error: 0.0410\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00145: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0376 - val_mean_absolute_error: 0.0376\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00146: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00147: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0612 - val_mean_absolute_error: 0.0612\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1369 - mean_absolute_error: 0.1369\n",
      "Epoch 00148: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1369 - mean_absolute_error: 0.1369 - val_loss: 0.0515 - val_mean_absolute_error: 0.0515\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1399 - mean_absolute_error: 0.1399\n",
      "Epoch 00149: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1399 - mean_absolute_error: 0.1399 - val_loss: 0.0459 - val_mean_absolute_error: 0.0459\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00150: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0397 - val_mean_absolute_error: 0.0397\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1392 - mean_absolute_error: 0.1392\n",
      "Epoch 00151: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1392 - mean_absolute_error: 0.1392 - val_loss: 0.0435 - val_mean_absolute_error: 0.0435\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1397 - mean_absolute_error: 0.1397\n",
      "Epoch 00152: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1397 - mean_absolute_error: 0.1397 - val_loss: 0.0622 - val_mean_absolute_error: 0.0622\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.1353\n",
      "Epoch 00153: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.0351 - val_mean_absolute_error: 0.0351\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1390 - mean_absolute_error: 0.1390\n",
      "Epoch 00154: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1350 - mean_absolute_error: 0.1350\n",
      "Epoch 00155: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1350 - mean_absolute_error: 0.1350 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.1359\n",
      "Epoch 00156: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1379 - mean_absolute_error: 0.1379\n",
      "Epoch 00157: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1379 - mean_absolute_error: 0.1379 - val_loss: 0.0628 - val_mean_absolute_error: 0.0628\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1352 - mean_absolute_error: 0.1352\n",
      "Epoch 00158: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.0436 - val_mean_absolute_error: 0.0436\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1346 - mean_absolute_error: 0.1346\n",
      "Epoch 00159: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1346 - mean_absolute_error: 0.1346 - val_loss: 0.0399 - val_mean_absolute_error: 0.0399\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1333 - mean_absolute_error: 0.1333\n",
      "Epoch 00160: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.1372\n",
      "Epoch 00161: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00162: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0515 - val_mean_absolute_error: 0.0515\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.1322\n",
      "Epoch 00163: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1348 - mean_absolute_error: 0.1348\n",
      "Epoch 00164: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 00165: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00166: val_loss did not improve from 0.02620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 00166: early stopping\n",
      "Model for  3  angles\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1651 - mean_absolute_error: 0.1651\n",
      "Epoch 00001: val_loss improved from inf to 0.08306, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1651 - mean_absolute_error: 0.1651 - val_loss: 0.0831 - val_mean_absolute_error: 0.0831\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1545 - mean_absolute_error: 0.1545\n",
      "Epoch 00002: val_loss did not improve from 0.08306\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1545 - mean_absolute_error: 0.1545 - val_loss: 0.0847 - val_mean_absolute_error: 0.0847\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1492 - mean_absolute_error: 0.1492\n",
      "Epoch 00003: val_loss improved from 0.08306 to 0.06809, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1492 - mean_absolute_error: 0.1492 - val_loss: 0.0681 - val_mean_absolute_error: 0.0681\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1496 - mean_absolute_error: 0.1496\n",
      "Epoch 00004: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1496 - mean_absolute_error: 0.1496 - val_loss: 0.0767 - val_mean_absolute_error: 0.0767\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1513 - mean_absolute_error: 0.1513\n",
      "Epoch 00005: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.0791 - val_mean_absolute_error: 0.0791\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1471 - mean_absolute_error: 0.1471\n",
      "Epoch 00006: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1471 - mean_absolute_error: 0.1471 - val_loss: 0.0690 - val_mean_absolute_error: 0.0690\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1425 - mean_absolute_error: 0.1425\n",
      "Epoch 00007: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1425 - mean_absolute_error: 0.1425 - val_loss: 0.0764 - val_mean_absolute_error: 0.0764\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1415 - mean_absolute_error: 0.1415\n",
      "Epoch 00008: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1415 - mean_absolute_error: 0.1415 - val_loss: 0.0864 - val_mean_absolute_error: 0.0864\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1413 - mean_absolute_error: 0.1413\n",
      "Epoch 00009: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1413 - mean_absolute_error: 0.1413 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1448 - mean_absolute_error: 0.1448\n",
      "Epoch 00010: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1448 - mean_absolute_error: 0.1448 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1404 - mean_absolute_error: 0.1404\n",
      "Epoch 00011: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.0800 - val_mean_absolute_error: 0.0800\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1457 - mean_absolute_error: 0.1457\n",
      "Epoch 00012: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1457 - mean_absolute_error: 0.1457 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 00013: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1445 - mean_absolute_error: 0.1445\n",
      "Epoch 00014: val_loss did not improve from 0.06809\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1445 - mean_absolute_error: 0.1445 - val_loss: 0.0797 - val_mean_absolute_error: 0.0797\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1435 - mean_absolute_error: 0.1435\n",
      "Epoch 00015: val_loss improved from 0.06809 to 0.06682, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1435 - mean_absolute_error: 0.1435 - val_loss: 0.0668 - val_mean_absolute_error: 0.0668\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1410 - mean_absolute_error: 0.1410\n",
      "Epoch 00016: val_loss did not improve from 0.06682\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1423 - mean_absolute_error: 0.1423\n",
      "Epoch 00017: val_loss improved from 0.06682 to 0.06541, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1423 - mean_absolute_error: 0.1423 - val_loss: 0.0654 - val_mean_absolute_error: 0.0654\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1418 - mean_absolute_error: 0.1418\n",
      "Epoch 00018: val_loss did not improve from 0.06541\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1416 - mean_absolute_error: 0.1416\n",
      "Epoch 00019: val_loss improved from 0.06541 to 0.06365, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.1416 - mean_absolute_error: 0.1416 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.1385\n",
      "Epoch 00020: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1410 - mean_absolute_error: 0.1410\n",
      "Epoch 00021: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - mean_absolute_error: 0.1365\n",
      "Epoch 00022: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.0862 - val_mean_absolute_error: 0.0862\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00023: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0660 - val_mean_absolute_error: 0.0660\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1390 - mean_absolute_error: 0.1390\n",
      "Epoch 00024: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1370 - mean_absolute_error: 0.1370\n",
      "Epoch 00025: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00026: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0757 - val_mean_absolute_error: 0.0757\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1409 - mean_absolute_error: 0.1409\n",
      "Epoch 00027: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1409 - mean_absolute_error: 0.1409 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1396 - mean_absolute_error: 0.1396\n",
      "Epoch 00028: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1383 - mean_absolute_error: 0.1383\n",
      "Epoch 00029: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1383 - mean_absolute_error: 0.1383 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1420 - mean_absolute_error: 0.1420\n",
      "Epoch 00030: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1420 - mean_absolute_error: 0.1420 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1404 - mean_absolute_error: 0.1404\n",
      "Epoch 00031: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1387 - mean_absolute_error: 0.1387\n",
      "Epoch 00032: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1419 - mean_absolute_error: 0.1419\n",
      "Epoch 00033: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1419 - mean_absolute_error: 0.1419 - val_loss: 0.0762 - val_mean_absolute_error: 0.0762\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1376 - mean_absolute_error: 0.1376\n",
      "Epoch 00034: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1376 - mean_absolute_error: 0.1376 - val_loss: 0.0931 - val_mean_absolute_error: 0.0931\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1411 - mean_absolute_error: 0.1411\n",
      "Epoch 00035: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1411 - mean_absolute_error: 0.1411 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1393 - mean_absolute_error: 0.1393\n",
      "Epoch 00036: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.0763 - val_mean_absolute_error: 0.0763\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1415 - mean_absolute_error: 0.1415\n",
      "Epoch 00037: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1415 - mean_absolute_error: 0.1415 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00038: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0786 - val_mean_absolute_error: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1384 - mean_absolute_error: 0.1384\n",
      "Epoch 00039: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1384 - mean_absolute_error: 0.1384 - val_loss: 0.0764 - val_mean_absolute_error: 0.0764\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1371 - mean_absolute_error: 0.1371\n",
      "Epoch 00040: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1371 - mean_absolute_error: 0.1371 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1389 - mean_absolute_error: 0.1389\n",
      "Epoch 00041: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1389 - mean_absolute_error: 0.1389 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00042: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1378 - mean_absolute_error: 0.1378\n",
      "Epoch 00043: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.0805 - val_mean_absolute_error: 0.0805\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1386 - mean_absolute_error: 0.1386\n",
      "Epoch 00044: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1386 - mean_absolute_error: 0.1386 - val_loss: 0.0664 - val_mean_absolute_error: 0.0664\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00045: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0765 - val_mean_absolute_error: 0.0765\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.1380\n",
      "Epoch 00046: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1375 - mean_absolute_error: 0.1375\n",
      "Epoch 00047: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1375 - mean_absolute_error: 0.1375 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.1362\n",
      "Epoch 00048: val_loss did not improve from 0.06365\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1381 - mean_absolute_error: 0.1381\n",
      "Epoch 00049: val_loss improved from 0.06365 to 0.06052, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00050: val_loss improved from 0.06052 to 0.05970, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00051: val_loss did not improve from 0.05970\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1358\n",
      "Epoch 00052: val_loss did not improve from 0.05970\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.1367\n",
      "Epoch 00053: val_loss improved from 0.05970 to 0.05736, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 00054: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1354\n",
      "Epoch 00055: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.1372\n",
      "Epoch 00056: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.0634 - val_mean_absolute_error: 0.0634\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - mean_absolute_error: 0.1365\n",
      "Epoch 00057: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.1353\n",
      "Epoch 00058: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1363 - mean_absolute_error: 0.1363\n",
      "Epoch 00059: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.0682 - val_mean_absolute_error: 0.0682\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1348 - mean_absolute_error: 0.1348\n",
      "Epoch 00060: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1351 - mean_absolute_error: 0.1351\n",
      "Epoch 00061: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1351 - mean_absolute_error: 0.1351 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.1342\n",
      "Epoch 00062: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1370 - mean_absolute_error: 0.1370\n",
      "Epoch 00063: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.0616 - val_mean_absolute_error: 0.0616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00064: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0737 - val_mean_absolute_error: 0.0737\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1344 - mean_absolute_error: 0.1344\n",
      "Epoch 00065: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1386 - mean_absolute_error: 0.1386\n",
      "Epoch 00066: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1386 - mean_absolute_error: 0.1386 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00067: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.1366\n",
      "Epoch 00068: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.0636 - val_mean_absolute_error: 0.0636\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1340 - mean_absolute_error: 0.1340\n",
      "Epoch 00069: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1346 - mean_absolute_error: 0.1346\n",
      "Epoch 00070: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1346 - mean_absolute_error: 0.1346 - val_loss: 0.0682 - val_mean_absolute_error: 0.0682\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1344 - mean_absolute_error: 0.1344\n",
      "Epoch 00071: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.0686 - val_mean_absolute_error: 0.0686\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - mean_absolute_error: 0.1365\n",
      "Epoch 00072: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.0841 - val_mean_absolute_error: 0.0841\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.1321\n",
      "Epoch 00073: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1321 - mean_absolute_error: 0.1321 - val_loss: 0.0640 - val_mean_absolute_error: 0.0640\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1349 - mean_absolute_error: 0.1349\n",
      "Epoch 00074: val_loss did not improve from 0.05736\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1349 - mean_absolute_error: 0.1349 - val_loss: 0.0664 - val_mean_absolute_error: 0.0664\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1354\n",
      "Epoch 00075: val_loss improved from 0.05736 to 0.05711, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1354\n",
      "Epoch 00076: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1364 - mean_absolute_error: 0.1364\n",
      "Epoch 00077: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1364 - mean_absolute_error: 0.1364 - val_loss: 0.0688 - val_mean_absolute_error: 0.0688\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1361 - mean_absolute_error: 0.1361\n",
      "Epoch 00078: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1345 - mean_absolute_error: 0.1345\n",
      "Epoch 00079: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1345 - mean_absolute_error: 0.1345 - val_loss: 0.0643 - val_mean_absolute_error: 0.0643\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1363 - mean_absolute_error: 0.1363\n",
      "Epoch 00080: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1327 - mean_absolute_error: 0.1327\n",
      "Epoch 00081: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1327 - mean_absolute_error: 0.1327 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1355 - mean_absolute_error: 0.1355\n",
      "Epoch 00082: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.0740 - val_mean_absolute_error: 0.0740\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1347 - mean_absolute_error: 0.1347\n",
      "Epoch 00083: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1355 - mean_absolute_error: 0.1355\n",
      "Epoch 00084: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1326 - mean_absolute_error: 0.1326\n",
      "Epoch 00085: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1326 - mean_absolute_error: 0.1326 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1340 - mean_absolute_error: 0.1340\n",
      "Epoch 00086: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1336 - mean_absolute_error: 0.1336\n",
      "Epoch 00087: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.0732 - val_mean_absolute_error: 0.0732\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1335 - mean_absolute_error: 0.1335\n",
      "Epoch 00088: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.0654 - val_mean_absolute_error: 0.0654\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1356 - mean_absolute_error: 0.1356\n",
      "Epoch 00089: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1348 - mean_absolute_error: 0.1348\n",
      "Epoch 00090: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1335 - mean_absolute_error: 0.1335\n",
      "Epoch 00091: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1334 - mean_absolute_error: 0.1334\n",
      "Epoch 00092: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1334 - mean_absolute_error: 0.1334 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1354\n",
      "Epoch 00093: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1323 - mean_absolute_error: 0.1323\n",
      "Epoch 00094: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.0627 - val_mean_absolute_error: 0.0627\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 00095: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1335 - mean_absolute_error: 0.1335\n",
      "Epoch 00096: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.0652 - val_mean_absolute_error: 0.0652\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.1342\n",
      "Epoch 00097: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1333 - mean_absolute_error: 0.1333\n",
      "Epoch 00098: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.0638 - val_mean_absolute_error: 0.0638\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1331 - mean_absolute_error: 0.1331\n",
      "Epoch 00099: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1331 - mean_absolute_error: 0.1331 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1333 - mean_absolute_error: 0.1333\n",
      "Epoch 00100: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.1322\n",
      "Epoch 00101: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1325 - mean_absolute_error: 0.1325\n",
      "Epoch 00102: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1325 - mean_absolute_error: 0.1325 - val_loss: 0.0736 - val_mean_absolute_error: 0.0736\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.1322\n",
      "Epoch 00103: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1311 - mean_absolute_error: 0.1311\n",
      "Epoch 00104: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1330 - mean_absolute_error: 0.1330\n",
      "Epoch 00105: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.0607 - val_mean_absolute_error: 0.0607\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1297 - mean_absolute_error: 0.1297\n",
      "Epoch 00106: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.0650 - val_mean_absolute_error: 0.0650\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1338 - mean_absolute_error: 0.1338\n",
      "Epoch 00107: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1338 - mean_absolute_error: 0.1338 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1320 - mean_absolute_error: 0.1320\n",
      "Epoch 00108: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.1342\n",
      "Epoch 00109: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.0663 - val_mean_absolute_error: 0.0663\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1316 - mean_absolute_error: 0.1316\n",
      "Epoch 00110: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1317 - mean_absolute_error: 0.1317\n",
      "Epoch 00111: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1317 - mean_absolute_error: 0.1317 - val_loss: 0.0744 - val_mean_absolute_error: 0.0744\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1318 - mean_absolute_error: 0.1318\n",
      "Epoch 00112: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1318 - mean_absolute_error: 0.1318 - val_loss: 0.0628 - val_mean_absolute_error: 0.0628\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1330 - mean_absolute_error: 0.1330\n",
      "Epoch 00113: val_loss did not improve from 0.05711\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1316 - mean_absolute_error: 0.1316\n",
      "Epoch 00114: val_loss improved from 0.05711 to 0.05625, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1312 - mean_absolute_error: 0.1312\n",
      "Epoch 00115: val_loss did not improve from 0.05625\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1312 - mean_absolute_error: 0.1312 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1303 - mean_absolute_error: 0.1303\n",
      "Epoch 00116: val_loss did not improve from 0.05625\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1303 - mean_absolute_error: 0.1303 - val_loss: 0.0564 - val_mean_absolute_error: 0.0564\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1306 - mean_absolute_error: 0.1306\n",
      "Epoch 00117: val_loss did not improve from 0.05625\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1306 - mean_absolute_error: 0.1306 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1327 - mean_absolute_error: 0.1327\n",
      "Epoch 00118: val_loss improved from 0.05625 to 0.04805, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_3.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1327 - mean_absolute_error: 0.1327 - val_loss: 0.0481 - val_mean_absolute_error: 0.0481\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1323 - mean_absolute_error: 0.1323\n",
      "Epoch 00119: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1302 - mean_absolute_error: 0.1302\n",
      "Epoch 00120: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1302 - mean_absolute_error: 0.1302 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1302 - mean_absolute_error: 0.1302\n",
      "Epoch 00121: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1302 - mean_absolute_error: 0.1302 - val_loss: 0.0584 - val_mean_absolute_error: 0.0584\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1326 - mean_absolute_error: 0.1326\n",
      "Epoch 00122: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1326 - mean_absolute_error: 0.1326 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1304 - mean_absolute_error: 0.1304\n",
      "Epoch 00123: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.0647 - val_mean_absolute_error: 0.0647\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1313 - mean_absolute_error: 0.1313\n",
      "Epoch 00124: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1313 - mean_absolute_error: 0.1313 - val_loss: 0.0587 - val_mean_absolute_error: 0.0587\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1296 - mean_absolute_error: 0.1296\n",
      "Epoch 00125: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1289 - mean_absolute_error: 0.1289\n",
      "Epoch 00126: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1289 - mean_absolute_error: 0.1289 - val_loss: 0.0745 - val_mean_absolute_error: 0.0745\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1320 - mean_absolute_error: 0.1320\n",
      "Epoch 00127: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1340 - mean_absolute_error: 0.1340\n",
      "Epoch 00128: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1306 - mean_absolute_error: 0.1306\n",
      "Epoch 00129: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1306 - mean_absolute_error: 0.1306 - val_loss: 0.0694 - val_mean_absolute_error: 0.0694\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1295 - mean_absolute_error: 0.1295\n",
      "Epoch 00130: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1295 - mean_absolute_error: 0.1295 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1310 - mean_absolute_error: 0.1310\n",
      "Epoch 00131: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1312 - mean_absolute_error: 0.1312\n",
      "Epoch 00132: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1312 - mean_absolute_error: 0.1312 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.1286\n",
      "Epoch 00133: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.0695 - val_mean_absolute_error: 0.0695\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1316 - mean_absolute_error: 0.1316\n",
      "Epoch 00134: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1314 - mean_absolute_error: 0.1314\n",
      "Epoch 00135: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1314 - mean_absolute_error: 0.1314 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1317 - mean_absolute_error: 0.1317\n",
      "Epoch 00136: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1317 - mean_absolute_error: 0.1317 - val_loss: 0.0864 - val_mean_absolute_error: 0.0864\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.1321\n",
      "Epoch 00137: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1321 - mean_absolute_error: 0.1321 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1339 - mean_absolute_error: 0.1339\n",
      "Epoch 00138: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.0732 - val_mean_absolute_error: 0.0732\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1300 - mean_absolute_error: 0.1300\n",
      "Epoch 00139: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1300 - mean_absolute_error: 0.1300 - val_loss: 0.0634 - val_mean_absolute_error: 0.0634\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.1243\n",
      "Epoch 00140: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1296 - mean_absolute_error: 0.1296\n",
      "Epoch 00141: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1304 - mean_absolute_error: 0.1304\n",
      "Epoch 00142: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.0650 - val_mean_absolute_error: 0.0650\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1301 - mean_absolute_error: 0.1301\n",
      "Epoch 00143: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1301 - mean_absolute_error: 0.1301 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1268 - mean_absolute_error: 0.1268\n",
      "Epoch 00144: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1268 - mean_absolute_error: 0.1268 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1297 - mean_absolute_error: 0.1297\n",
      "Epoch 00145: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1282 - mean_absolute_error: 0.1282\n",
      "Epoch 00146: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.1286\n",
      "Epoch 00147: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.0675 - val_mean_absolute_error: 0.0675\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.1257\n",
      "Epoch 00148: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.1278\n",
      "Epoch 00149: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1278 - mean_absolute_error: 0.1278 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1281 - mean_absolute_error: 0.1281\n",
      "Epoch 00150: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.0760 - val_mean_absolute_error: 0.0760\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1275 - mean_absolute_error: 0.1275\n",
      "Epoch 00151: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1292 - mean_absolute_error: 0.1292\n",
      "Epoch 00152: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.0603 - val_mean_absolute_error: 0.0603\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1280 - mean_absolute_error: 0.1280\n",
      "Epoch 00153: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.1267\n",
      "Epoch 00154: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1288 - mean_absolute_error: 0.1288\n",
      "Epoch 00155: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1279 - mean_absolute_error: 0.1279\n",
      "Epoch 00156: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1287 - mean_absolute_error: 0.1287\n",
      "Epoch 00157: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.1267\n",
      "Epoch 00158: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1298 - mean_absolute_error: 0.1298\n",
      "Epoch 00159: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1298 - mean_absolute_error: 0.1298 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1246 - mean_absolute_error: 0.1246\n",
      "Epoch 00160: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1246 - mean_absolute_error: 0.1246 - val_loss: 0.0576 - val_mean_absolute_error: 0.0576\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.1278\n",
      "Epoch 00161: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1278 - mean_absolute_error: 0.1278 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1283 - mean_absolute_error: 0.1283\n",
      "Epoch 00162: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.0635 - val_mean_absolute_error: 0.0635\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.1305\n",
      "Epoch 00163: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.1250\n",
      "Epoch 00164: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1268 - mean_absolute_error: 0.1268\n",
      "Epoch 00165: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1268 - mean_absolute_error: 0.1268 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.1286\n",
      "Epoch 00166: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1254 - mean_absolute_error: 0.1254\n",
      "Epoch 00167: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.0575 - val_mean_absolute_error: 0.0575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1254 - mean_absolute_error: 0.1254\n",
      "Epoch 00168: val_loss did not improve from 0.04805\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.0633 - val_mean_absolute_error: 0.0633\n",
      "Epoch 00168: early stopping\n",
      "Model for  4  angles\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1510 - mean_absolute_error: 0.1510\n",
      "Epoch 00001: val_loss improved from inf to 0.10005, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1001 - val_mean_absolute_error: 0.1001\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1345 - mean_absolute_error: 0.1345\n",
      "Epoch 00002: val_loss improved from 0.10005 to 0.09349, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1345 - mean_absolute_error: 0.1345 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.1286\n",
      "Epoch 00003: val_loss did not improve from 0.09349\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.0942 - val_mean_absolute_error: 0.0942\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1282 - mean_absolute_error: 0.1282\n",
      "Epoch 00004: val_loss improved from 0.09349 to 0.08764, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.1250\n",
      "Epoch 00005: val_loss did not improve from 0.08764\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.0879 - val_mean_absolute_error: 0.0879\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.1243\n",
      "Epoch 00006: val_loss did not improve from 0.08764\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1219 - mean_absolute_error: 0.1219\n",
      "Epoch 00007: val_loss did not improve from 0.08764\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.0889 - val_mean_absolute_error: 0.0889\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.1211\n",
      "Epoch 00008: val_loss improved from 0.08764 to 0.08763, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1211 - mean_absolute_error: 0.1211 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.1164\n",
      "Epoch 00009: val_loss did not improve from 0.08763\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1164 - mean_absolute_error: 0.1164 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.1176\n",
      "Epoch 00010: val_loss improved from 0.08763 to 0.08150, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.1168\n",
      "Epoch 00011: val_loss did not improve from 0.08150\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1168 - mean_absolute_error: 0.1168 - val_loss: 0.0819 - val_mean_absolute_error: 0.0819\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.1198\n",
      "Epoch 00012: val_loss improved from 0.08150 to 0.08014, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1198 - mean_absolute_error: 0.1198 - val_loss: 0.0801 - val_mean_absolute_error: 0.0801\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.1176\n",
      "Epoch 00013: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.1176\n",
      "Epoch 00014: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.0956 - val_mean_absolute_error: 0.0956\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.1193\n",
      "Epoch 00015: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1193 - mean_absolute_error: 0.1193 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.1188\n",
      "Epoch 00016: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1188 - mean_absolute_error: 0.1188 - val_loss: 0.0822 - val_mean_absolute_error: 0.0822\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.1184\n",
      "Epoch 00017: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1184 - mean_absolute_error: 0.1184 - val_loss: 0.0877 - val_mean_absolute_error: 0.0877\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.1176\n",
      "Epoch 00018: val_loss did not improve from 0.08014\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.1207\n",
      "Epoch 00019: val_loss improved from 0.08014 to 0.07801, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1207 - mean_absolute_error: 0.1207 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.1212\n",
      "Epoch 00020: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.1152\n",
      "Epoch 00021: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1152 - mean_absolute_error: 0.1152 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.1152\n",
      "Epoch 00022: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1152 - mean_absolute_error: 0.1152 - val_loss: 0.0891 - val_mean_absolute_error: 0.0891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.1155\n",
      "Epoch 00023: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1155 - mean_absolute_error: 0.1155 - val_loss: 0.0899 - val_mean_absolute_error: 0.0899\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.1156\n",
      "Epoch 00024: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1156 - mean_absolute_error: 0.1156 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.1171\n",
      "Epoch 00025: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1171 - mean_absolute_error: 0.1171 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.1148\n",
      "Epoch 00026: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1148 - mean_absolute_error: 0.1148 - val_loss: 0.0846 - val_mean_absolute_error: 0.0846\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.1174\n",
      "Epoch 00027: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1174 - mean_absolute_error: 0.1174 - val_loss: 0.0828 - val_mean_absolute_error: 0.0828\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1136 - mean_absolute_error: 0.1136\n",
      "Epoch 00028: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1136 - mean_absolute_error: 0.1136 - val_loss: 0.0880 - val_mean_absolute_error: 0.0880\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.1154\n",
      "Epoch 00029: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1154 - mean_absolute_error: 0.1154 - val_loss: 0.0797 - val_mean_absolute_error: 0.0797\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.1171\n",
      "Epoch 00030: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1171 - mean_absolute_error: 0.1171 - val_loss: 0.0835 - val_mean_absolute_error: 0.0835\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1150 - mean_absolute_error: 0.1150\n",
      "Epoch 00031: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.1147\n",
      "Epoch 00032: val_loss did not improve from 0.07801\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1147 - mean_absolute_error: 0.1147 - val_loss: 0.0844 - val_mean_absolute_error: 0.0844\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.1147\n",
      "Epoch 00033: val_loss improved from 0.07801 to 0.07746, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1147 - mean_absolute_error: 0.1147 - val_loss: 0.0775 - val_mean_absolute_error: 0.0775\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.1164\n",
      "Epoch 00034: val_loss did not improve from 0.07746\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1164 - mean_absolute_error: 0.1164 - val_loss: 0.0832 - val_mean_absolute_error: 0.0832\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1135 - mean_absolute_error: 0.1135\n",
      "Epoch 00035: val_loss did not improve from 0.07746\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1135 - mean_absolute_error: 0.1135 - val_loss: 0.0864 - val_mean_absolute_error: 0.0864\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.1143\n",
      "Epoch 00036: val_loss improved from 0.07746 to 0.07601, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.0760 - val_mean_absolute_error: 0.0760\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1157 - mean_absolute_error: 0.1157\n",
      "Epoch 00037: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1157 - mean_absolute_error: 0.1157 - val_loss: 0.0807 - val_mean_absolute_error: 0.0807\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1160 - mean_absolute_error: 0.1160\n",
      "Epoch 00038: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1160 - mean_absolute_error: 0.1160 - val_loss: 0.0812 - val_mean_absolute_error: 0.0812\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.1163\n",
      "Epoch 00039: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1163 - mean_absolute_error: 0.1163 - val_loss: 0.0854 - val_mean_absolute_error: 0.0854\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.1138\n",
      "Epoch 00040: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1138 - mean_absolute_error: 0.1138 - val_loss: 0.0838 - val_mean_absolute_error: 0.0838\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.1156\n",
      "Epoch 00041: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1156 - mean_absolute_error: 0.1156 - val_loss: 0.0802 - val_mean_absolute_error: 0.0802\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.1139\n",
      "Epoch 00042: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.0810 - val_mean_absolute_error: 0.0810\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.1139\n",
      "Epoch 00043: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.0797 - val_mean_absolute_error: 0.0797\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.1155\n",
      "Epoch 00044: val_loss did not improve from 0.07601\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1155 - mean_absolute_error: 0.1155 - val_loss: 0.0849 - val_mean_absolute_error: 0.0849\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1116 - mean_absolute_error: 0.1116\n",
      "Epoch 00045: val_loss improved from 0.07601 to 0.07379, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1116 - mean_absolute_error: 0.1116 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1150 - mean_absolute_error: 0.1150\n",
      "Epoch 00046: val_loss did not improve from 0.07379\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.0859 - val_mean_absolute_error: 0.0859\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1150 - mean_absolute_error: 0.1150\n",
      "Epoch 00047: val_loss did not improve from 0.07379\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.1133\n",
      "Epoch 00048: val_loss did not improve from 0.07379\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.0792 - val_mean_absolute_error: 0.0792\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1122 - mean_absolute_error: 0.1122\n",
      "Epoch 00049: val_loss improved from 0.07379 to 0.07015, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_4.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1122 - mean_absolute_error: 0.1122 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.1133\n",
      "Epoch 00050: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.0792 - val_mean_absolute_error: 0.0792\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1122 - mean_absolute_error: 0.1122\n",
      "Epoch 00051: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1122 - mean_absolute_error: 0.1122 - val_loss: 0.0811 - val_mean_absolute_error: 0.0811\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.1147\n",
      "Epoch 00052: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1147 - mean_absolute_error: 0.1147 - val_loss: 0.0817 - val_mean_absolute_error: 0.0817\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.1152\n",
      "Epoch 00053: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1152 - mean_absolute_error: 0.1152 - val_loss: 0.0866 - val_mean_absolute_error: 0.0866\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1145 - mean_absolute_error: 0.1145\n",
      "Epoch 00054: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.0799 - val_mean_absolute_error: 0.0799\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1137 - mean_absolute_error: 0.1137\n",
      "Epoch 00055: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1137 - mean_absolute_error: 0.1137 - val_loss: 0.0818 - val_mean_absolute_error: 0.0818\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.1125\n",
      "Epoch 00056: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1125 - mean_absolute_error: 0.1125 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.1156\n",
      "Epoch 00057: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1156 - mean_absolute_error: 0.1156 - val_loss: 0.0777 - val_mean_absolute_error: 0.0777\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1140 - mean_absolute_error: 0.1140\n",
      "Epoch 00058: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1140 - mean_absolute_error: 0.1140 - val_loss: 0.0779 - val_mean_absolute_error: 0.0779\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.1147\n",
      "Epoch 00059: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1147 - mean_absolute_error: 0.1147 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1129 - mean_absolute_error: 0.1129\n",
      "Epoch 00060: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1129 - mean_absolute_error: 0.1129 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.1138\n",
      "Epoch 00061: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1138 - mean_absolute_error: 0.1138 - val_loss: 0.0725 - val_mean_absolute_error: 0.0725\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.1132\n",
      "Epoch 00062: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.0824 - val_mean_absolute_error: 0.0824\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1162 - mean_absolute_error: 0.1162\n",
      "Epoch 00063: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1162 - mean_absolute_error: 0.1162 - val_loss: 0.0855 - val_mean_absolute_error: 0.0855\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1162 - mean_absolute_error: 0.1162\n",
      "Epoch 00064: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1162 - mean_absolute_error: 0.1162 - val_loss: 0.0867 - val_mean_absolute_error: 0.0867\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.1168\n",
      "Epoch 00065: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1168 - mean_absolute_error: 0.1168 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.1138\n",
      "Epoch 00066: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1138 - mean_absolute_error: 0.1138 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.1132\n",
      "Epoch 00067: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1141 - mean_absolute_error: 0.1141\n",
      "Epoch 00068: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1141 - mean_absolute_error: 0.1141 - val_loss: 0.0786 - val_mean_absolute_error: 0.0786\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.1124\n",
      "Epoch 00069: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.0837 - val_mean_absolute_error: 0.0837\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.1131\n",
      "Epoch 00070: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1131 - mean_absolute_error: 0.1131 - val_loss: 0.0839 - val_mean_absolute_error: 0.0839\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1136 - mean_absolute_error: 0.1136\n",
      "Epoch 00071: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1136 - mean_absolute_error: 0.1136 - val_loss: 0.0790 - val_mean_absolute_error: 0.0790\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1118 - mean_absolute_error: 0.1118\n",
      "Epoch 00072: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1118 - mean_absolute_error: 0.1118 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.1131\n",
      "Epoch 00073: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1131 - mean_absolute_error: 0.1131 - val_loss: 0.0730 - val_mean_absolute_error: 0.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1142 - mean_absolute_error: 0.1142\n",
      "Epoch 00074: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1142 - mean_absolute_error: 0.1142 - val_loss: 0.0896 - val_mean_absolute_error: 0.0896\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.1127\n",
      "Epoch 00075: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1127 - mean_absolute_error: 0.1127 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.1131\n",
      "Epoch 00076: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1131 - mean_absolute_error: 0.1131 - val_loss: 0.0787 - val_mean_absolute_error: 0.0787\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.1133\n",
      "Epoch 00077: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.0845 - val_mean_absolute_error: 0.0845\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.1125\n",
      "Epoch 00078: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1125 - mean_absolute_error: 0.1125 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1113 - mean_absolute_error: 0.1113\n",
      "Epoch 00079: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1113 - mean_absolute_error: 0.1113 - val_loss: 0.0750 - val_mean_absolute_error: 0.0750\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.1130\n",
      "Epoch 00080: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1123 - mean_absolute_error: 0.1123\n",
      "Epoch 00081: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1123 - mean_absolute_error: 0.1123 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1142 - mean_absolute_error: 0.1142\n",
      "Epoch 00082: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1142 - mean_absolute_error: 0.1142 - val_loss: 0.0878 - val_mean_absolute_error: 0.0878\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1107 - mean_absolute_error: 0.1107\n",
      "Epoch 00083: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1107 - mean_absolute_error: 0.1107 - val_loss: 0.0745 - val_mean_absolute_error: 0.0745\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1141 - mean_absolute_error: 0.1141\n",
      "Epoch 00084: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1141 - mean_absolute_error: 0.1141 - val_loss: 0.0793 - val_mean_absolute_error: 0.0793\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.1127\n",
      "Epoch 00085: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1127 - mean_absolute_error: 0.1127 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.1143\n",
      "Epoch 00086: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1111 - mean_absolute_error: 0.1111\n",
      "Epoch 00087: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.0903 - val_mean_absolute_error: 0.0903\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.1127\n",
      "Epoch 00088: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1127 - mean_absolute_error: 0.1127 - val_loss: 0.0791 - val_mean_absolute_error: 0.0791\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1129 - mean_absolute_error: 0.1129\n",
      "Epoch 00089: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1129 - mean_absolute_error: 0.1129 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.1143\n",
      "Epoch 00090: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.1138\n",
      "Epoch 00091: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1138 - mean_absolute_error: 0.1138 - val_loss: 0.0822 - val_mean_absolute_error: 0.0822\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.1124\n",
      "Epoch 00092: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.0760 - val_mean_absolute_error: 0.0760\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1137 - mean_absolute_error: 0.1137\n",
      "Epoch 00093: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1137 - mean_absolute_error: 0.1137 - val_loss: 0.0898 - val_mean_absolute_error: 0.0898\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.1124\n",
      "Epoch 00094: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1118 - mean_absolute_error: 0.1118\n",
      "Epoch 00095: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1118 - mean_absolute_error: 0.1118 - val_loss: 0.0844 - val_mean_absolute_error: 0.0844\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.1133\n",
      "Epoch 00096: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.0809 - val_mean_absolute_error: 0.0809\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.1139\n",
      "Epoch 00097: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1114 - mean_absolute_error: 0.1114\n",
      "Epoch 00098: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1114 - mean_absolute_error: 0.1114 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.1125\n",
      "Epoch 00099: val_loss did not improve from 0.07015\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1125 - mean_absolute_error: 0.1125 - val_loss: 0.0830 - val_mean_absolute_error: 0.0830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00099: early stopping\n",
      "Model for  5  angles\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1445 - mean_absolute_error: 0.1445\n",
      "Epoch 00001: val_loss improved from inf to 0.06813, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1445 - mean_absolute_error: 0.1445 - val_loss: 0.0681 - val_mean_absolute_error: 0.0681\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1249 - mean_absolute_error: 0.1249\n",
      "Epoch 00002: val_loss did not improve from 0.06813\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.1180\n",
      "Epoch 00003: val_loss improved from 0.06813 to 0.06169, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1180 - mean_absolute_error: 0.1180 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1126 - mean_absolute_error: 0.1126\n",
      "Epoch 00004: val_loss did not improve from 0.06169\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1126 - mean_absolute_error: 0.1126 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1104 - mean_absolute_error: 0.1104\n",
      "Epoch 00005: val_loss improved from 0.06169 to 0.06050, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1104 - mean_absolute_error: 0.1104 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1056 - mean_absolute_error: 0.1056\n",
      "Epoch 00006: val_loss improved from 0.06050 to 0.05931, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.1056 - mean_absolute_error: 0.1056 - val_loss: 0.0593 - val_mean_absolute_error: 0.0593\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1061 - mean_absolute_error: 0.1061\n",
      "Epoch 00007: val_loss improved from 0.05931 to 0.05620, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1061 - mean_absolute_error: 0.1061 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1049 - mean_absolute_error: 0.1049\n",
      "Epoch 00008: val_loss did not improve from 0.05620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1049 - mean_absolute_error: 0.1049 - val_loss: 0.0601 - val_mean_absolute_error: 0.0601\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1031 - mean_absolute_error: 0.1031\n",
      "Epoch 00009: val_loss did not improve from 0.05620\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1031 - mean_absolute_error: 0.1031 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1028 - mean_absolute_error: 0.1028\n",
      "Epoch 00010: val_loss improved from 0.05620 to 0.05517, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1028 - mean_absolute_error: 0.1028 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1022 - mean_absolute_error: 0.1022\n",
      "Epoch 00011: val_loss did not improve from 0.05517\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1022 - mean_absolute_error: 0.1022 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1025 - mean_absolute_error: 0.1025\n",
      "Epoch 00012: val_loss did not improve from 0.05517\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1029 - mean_absolute_error: 0.1029\n",
      "Epoch 00013: val_loss did not improve from 0.05517\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1029 - mean_absolute_error: 0.1029 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.1035\n",
      "Epoch 00014: val_loss did not improve from 0.05517\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.0610 - val_mean_absolute_error: 0.0610\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1011 - mean_absolute_error: 0.1011\n",
      "Epoch 00015: val_loss improved from 0.05517 to 0.05183, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1011 - mean_absolute_error: 0.1011 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1011 - mean_absolute_error: 0.1011\n",
      "Epoch 00016: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1011 - mean_absolute_error: 0.1011 - val_loss: 0.0612 - val_mean_absolute_error: 0.0612\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1010 - mean_absolute_error: 0.1010\n",
      "Epoch 00017: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1010 - mean_absolute_error: 0.1010 - val_loss: 0.0567 - val_mean_absolute_error: 0.0567\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0994 - mean_absolute_error: 0.0994\n",
      "Epoch 00018: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0994 - mean_absolute_error: 0.0994 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0987 - mean_absolute_error: 0.0987\n",
      "Epoch 00019: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0987 - mean_absolute_error: 0.0987 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0978 - mean_absolute_error: 0.0978\n",
      "Epoch 00020: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0978 - mean_absolute_error: 0.0978 - val_loss: 0.0528 - val_mean_absolute_error: 0.0528\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0989 - mean_absolute_error: 0.0989\n",
      "Epoch 00021: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0989 - mean_absolute_error: 0.0989 - val_loss: 0.0578 - val_mean_absolute_error: 0.0578\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0991 - mean_absolute_error: 0.0991\n",
      "Epoch 00022: val_loss did not improve from 0.05183\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0991 - mean_absolute_error: 0.0991 - val_loss: 0.0523 - val_mean_absolute_error: 0.0523\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0989 - mean_absolute_error: 0.0989\n",
      "Epoch 00023: val_loss improved from 0.05183 to 0.04936, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0989 - mean_absolute_error: 0.0989 - val_loss: 0.0494 - val_mean_absolute_error: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0985 - mean_absolute_error: 0.0985\n",
      "Epoch 00024: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0985 - mean_absolute_error: 0.0985 - val_loss: 0.0515 - val_mean_absolute_error: 0.0515\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0985 - mean_absolute_error: 0.0985\n",
      "Epoch 00025: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0985 - mean_absolute_error: 0.0985 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0967 - mean_absolute_error: 0.0967\n",
      "Epoch 00026: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0967 - mean_absolute_error: 0.0967 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0977 - mean_absolute_error: 0.0977\n",
      "Epoch 00027: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0977 - mean_absolute_error: 0.0977 - val_loss: 0.0569 - val_mean_absolute_error: 0.0569\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00028: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0504 - val_mean_absolute_error: 0.0504\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.0968\n",
      "Epoch 00029: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0968 - mean_absolute_error: 0.0968 - val_loss: 0.0511 - val_mean_absolute_error: 0.0511\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0971 - mean_absolute_error: 0.0971\n",
      "Epoch 00030: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0971 - mean_absolute_error: 0.0971 - val_loss: 0.0505 - val_mean_absolute_error: 0.0505\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0984 - mean_absolute_error: 0.0984\n",
      "Epoch 00031: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0984 - mean_absolute_error: 0.0984 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0962 - mean_absolute_error: 0.0962\n",
      "Epoch 00032: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0962 - mean_absolute_error: 0.0962 - val_loss: 0.0514 - val_mean_absolute_error: 0.0514\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0977 - mean_absolute_error: 0.0977\n",
      "Epoch 00033: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0977 - mean_absolute_error: 0.0977 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.0968\n",
      "Epoch 00034: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0968 - mean_absolute_error: 0.0968 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_error: 0.0966\n",
      "Epoch 00035: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0966 - mean_absolute_error: 0.0966 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0963 - mean_absolute_error: 0.0963\n",
      "Epoch 00036: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.0534 - val_mean_absolute_error: 0.0534\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.0968\n",
      "Epoch 00037: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0968 - mean_absolute_error: 0.0968 - val_loss: 0.0494 - val_mean_absolute_error: 0.0494\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0970 - mean_absolute_error: 0.0970\n",
      "Epoch 00038: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0970 - mean_absolute_error: 0.0970 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00039: val_loss did not improve from 0.04936\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0978 - mean_absolute_error: 0.0978\n",
      "Epoch 00040: val_loss improved from 0.04936 to 0.04782, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0978 - mean_absolute_error: 0.0978 - val_loss: 0.0478 - val_mean_absolute_error: 0.0478\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_error: 0.0966\n",
      "Epoch 00041: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0966 - mean_absolute_error: 0.0966 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1003 - mean_absolute_error: 0.1003\n",
      "Epoch 00042: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1003 - mean_absolute_error: 0.1003 - val_loss: 0.0622 - val_mean_absolute_error: 0.0622\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0991 - mean_absolute_error: 0.0991\n",
      "Epoch 00043: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0991 - mean_absolute_error: 0.0991 - val_loss: 0.0545 - val_mean_absolute_error: 0.0545\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_error: 0.0966\n",
      "Epoch 00044: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0966 - mean_absolute_error: 0.0966 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0979 - mean_absolute_error: 0.0979\n",
      "Epoch 00045: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0979 - mean_absolute_error: 0.0979 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00046: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0519 - val_mean_absolute_error: 0.0519\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0946 - mean_absolute_error: 0.0946\n",
      "Epoch 00047: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0946 - mean_absolute_error: 0.0946 - val_loss: 0.0479 - val_mean_absolute_error: 0.0479\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0972 - mean_absolute_error: 0.0972\n",
      "Epoch 00048: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0972 - mean_absolute_error: 0.0972 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00049: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0554 - val_mean_absolute_error: 0.0554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0944 - mean_absolute_error: 0.0944\n",
      "Epoch 00050: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.0504 - val_mean_absolute_error: 0.0504\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 00051: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0971 - mean_absolute_error: 0.0971\n",
      "Epoch 00052: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0971 - mean_absolute_error: 0.0971 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0945 - mean_absolute_error: 0.0945\n",
      "Epoch 00053: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0945 - mean_absolute_error: 0.0945 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0992 - mean_absolute_error: 0.0992\n",
      "Epoch 00054: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.0535 - val_mean_absolute_error: 0.0535\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.0955\n",
      "Epoch 00055: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0955 - mean_absolute_error: 0.0955 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.0955\n",
      "Epoch 00056: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0955 - mean_absolute_error: 0.0955 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00057: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0505 - val_mean_absolute_error: 0.0505\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00058: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0494 - val_mean_absolute_error: 0.0494\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0947 - mean_absolute_error: 0.0947\n",
      "Epoch 00059: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00060: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0960 - mean_absolute_error: 0.0960\n",
      "Epoch 00061: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0960 - mean_absolute_error: 0.0960 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0947 - mean_absolute_error: 0.0947\n",
      "Epoch 00062: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.0496 - val_mean_absolute_error: 0.0496\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00063: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0958 - mean_absolute_error: 0.0958\n",
      "Epoch 00064: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0958 - mean_absolute_error: 0.0958 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00065: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0567 - val_mean_absolute_error: 0.0567\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0961 - mean_absolute_error: 0.0961\n",
      "Epoch 00066: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.0532 - val_mean_absolute_error: 0.0532\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0959 - mean_absolute_error: 0.0959\n",
      "Epoch 00067: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0959 - mean_absolute_error: 0.0959 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.0949\n",
      "Epoch 00068: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.0955\n",
      "Epoch 00069: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0955 - mean_absolute_error: 0.0955 - val_loss: 0.0485 - val_mean_absolute_error: 0.0485\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.0949\n",
      "Epoch 00070: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.0942\n",
      "Epoch 00071: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.0954\n",
      "Epoch 00072: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.0527 - val_mean_absolute_error: 0.0527\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 00073: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.0534 - val_mean_absolute_error: 0.0534\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0967 - mean_absolute_error: 0.0967\n",
      "Epoch 00074: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0967 - mean_absolute_error: 0.0967 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00075: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0960 - mean_absolute_error: 0.0960\n",
      "Epoch 00076: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0960 - mean_absolute_error: 0.0960 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00077: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0521 - val_mean_absolute_error: 0.0521\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00078: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0936 - mean_absolute_error: 0.0936\n",
      "Epoch 00079: val_loss did not improve from 0.04782\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0936 - mean_absolute_error: 0.0936 - val_loss: 0.0528 - val_mean_absolute_error: 0.0528\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00080: val_loss improved from 0.04782 to 0.04574, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0945 - mean_absolute_error: 0.0945\n",
      "Epoch 00081: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0945 - mean_absolute_error: 0.0945 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0952 - mean_absolute_error: 0.0952\n",
      "Epoch 00082: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0952 - mean_absolute_error: 0.0952 - val_loss: 0.0548 - val_mean_absolute_error: 0.0548\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00083: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00084: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00085: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0584 - val_mean_absolute_error: 0.0584\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00086: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00087: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0505 - val_mean_absolute_error: 0.0505\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 00088: val_loss did not improve from 0.04574\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.0471 - val_mean_absolute_error: 0.0471\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.0949\n",
      "Epoch 00089: val_loss improved from 0.04574 to 0.04422, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_5.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0442 - val_mean_absolute_error: 0.0442\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00090: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0501 - val_mean_absolute_error: 0.0501\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.0954\n",
      "Epoch 00091: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.0557 - val_mean_absolute_error: 0.0557\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.0942\n",
      "Epoch 00092: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.0545 - val_mean_absolute_error: 0.0545\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00093: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00094: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0516 - val_mean_absolute_error: 0.0516\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.0941\n",
      "Epoch 00095: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0941 - mean_absolute_error: 0.0941 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.0934\n",
      "Epoch 00096: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 00097: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.0942\n",
      "Epoch 00098: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.0934\n",
      "Epoch 00099: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.0504 - val_mean_absolute_error: 0.0504\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 00100: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00101: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0502 - val_mean_absolute_error: 0.0502\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.0932\n",
      "Epoch 00102: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.0932\n",
      "Epoch 00103: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.0491 - val_mean_absolute_error: 0.0491\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0945 - mean_absolute_error: 0.0945\n",
      "Epoch 00104: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0945 - mean_absolute_error: 0.0945 - val_loss: 0.0493 - val_mean_absolute_error: 0.0493\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0936 - mean_absolute_error: 0.0936\n",
      "Epoch 00105: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0936 - mean_absolute_error: 0.0936 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.0933\n",
      "Epoch 00106: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0933 - mean_absolute_error: 0.0933 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 00107: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.0477 - val_mean_absolute_error: 0.0477\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00108: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0943 - mean_absolute_error: 0.0943\n",
      "Epoch 00109: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0943 - mean_absolute_error: 0.0943 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00110: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0460 - val_mean_absolute_error: 0.0460\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.0949\n",
      "Epoch 00111: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0917 - mean_absolute_error: 0.0917\n",
      "Epoch 00112: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00113: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 00114: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.0505 - val_mean_absolute_error: 0.0505\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0946 - mean_absolute_error: 0.0946\n",
      "Epoch 00115: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0946 - mean_absolute_error: 0.0946 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0944 - mean_absolute_error: 0.0944\n",
      "Epoch 00116: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.0934\n",
      "Epoch 00117: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.0496 - val_mean_absolute_error: 0.0496\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 00118: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.0923\n",
      "Epoch 00119: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.0497 - val_mean_absolute_error: 0.0497\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00120: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0519 - val_mean_absolute_error: 0.0519\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0936 - mean_absolute_error: 0.0936\n",
      "Epoch 00121: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0936 - mean_absolute_error: 0.0936 - val_loss: 0.0545 - val_mean_absolute_error: 0.0545\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0935 - mean_absolute_error: 0.0935\n",
      "Epoch 00122: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0935 - mean_absolute_error: 0.0935 - val_loss: 0.0545 - val_mean_absolute_error: 0.0545\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.0933\n",
      "Epoch 00123: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0933 - mean_absolute_error: 0.0933 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.0931\n",
      "Epoch 00124: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0931 - mean_absolute_error: 0.0931 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 00125: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.0941\n",
      "Epoch 00126: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0941 - mean_absolute_error: 0.0941 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0935 - mean_absolute_error: 0.0935\n",
      "Epoch 00127: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0935 - mean_absolute_error: 0.0935 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.0923\n",
      "Epoch 00128: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.0520 - val_mean_absolute_error: 0.0520\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0912 - mean_absolute_error: 0.0912\n",
      "Epoch 00129: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.0931\n",
      "Epoch 00130: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0931 - mean_absolute_error: 0.0931 - val_loss: 0.0463 - val_mean_absolute_error: 0.0463\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0920 - mean_absolute_error: 0.0920\n",
      "Epoch 00131: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0920 - mean_absolute_error: 0.0920 - val_loss: 0.0446 - val_mean_absolute_error: 0.0446\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00132: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0938 - mean_absolute_error: 0.0938\n",
      "Epoch 00133: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.0482 - val_mean_absolute_error: 0.0482\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0925 - mean_absolute_error: 0.0925\n",
      "Epoch 00134: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.0483 - val_mean_absolute_error: 0.0483\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0943 - mean_absolute_error: 0.0943\n",
      "Epoch 00135: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0943 - mean_absolute_error: 0.0943 - val_loss: 0.0495 - val_mean_absolute_error: 0.0495\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.0926\n",
      "Epoch 00136: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0926 - mean_absolute_error: 0.0926 - val_loss: 0.0477 - val_mean_absolute_error: 0.0477\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00137: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.0926\n",
      "Epoch 00138: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0926 - mean_absolute_error: 0.0926 - val_loss: 0.0478 - val_mean_absolute_error: 0.0478\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 00139: val_loss did not improve from 0.04422\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.0464 - val_mean_absolute_error: 0.0464\n",
      "Epoch 00139: early stopping\n",
      "Model for  6  angles\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1409 - mean_absolute_error: 0.1409\n",
      "Epoch 00001: val_loss improved from inf to 0.09478, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1409 - mean_absolute_error: 0.1409 - val_loss: 0.0948 - val_mean_absolute_error: 0.0948\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.1243\n",
      "Epoch 00002: val_loss improved from 0.09478 to 0.08825, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.0883 - val_mean_absolute_error: 0.0883\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.1164\n",
      "Epoch 00003: val_loss improved from 0.08825 to 0.08107, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1164 - mean_absolute_error: 0.1164 - val_loss: 0.0811 - val_mean_absolute_error: 0.0811\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1110 - mean_absolute_error: 0.1110\n",
      "Epoch 00004: val_loss improved from 0.08107 to 0.07606, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1110 - mean_absolute_error: 0.1110 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1090 - mean_absolute_error: 0.1090\n",
      "Epoch 00005: val_loss did not improve from 0.07606\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1090 - mean_absolute_error: 0.1090 - val_loss: 0.0806 - val_mean_absolute_error: 0.0806\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1054 - mean_absolute_error: 0.1054\n",
      "Epoch 00006: val_loss improved from 0.07606 to 0.07573, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1054 - mean_absolute_error: 0.1054 - val_loss: 0.0757 - val_mean_absolute_error: 0.0757\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.1035\n",
      "Epoch 00007: val_loss did not improve from 0.07573\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.0790 - val_mean_absolute_error: 0.0790\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1027 - mean_absolute_error: 0.1027\n",
      "Epoch 00008: val_loss did not improve from 0.07573\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1027 - mean_absolute_error: 0.1027 - val_loss: 0.0762 - val_mean_absolute_error: 0.0762\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1024 - mean_absolute_error: 0.1024\n",
      "Epoch 00009: val_loss did not improve from 0.07573\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.1024 - mean_absolute_error: 0.1024 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1011 - mean_absolute_error: 0.1011\n",
      "Epoch 00010: val_loss did not improve from 0.07573\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1011 - mean_absolute_error: 0.1011 - val_loss: 0.0829 - val_mean_absolute_error: 0.0829\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1007 - mean_absolute_error: 0.1007\n",
      "Epoch 00011: val_loss did not improve from 0.07573\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1007 - mean_absolute_error: 0.1007 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0992 - mean_absolute_error: 0.0992\n",
      "Epoch 00012: val_loss improved from 0.07573 to 0.07394, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0984 - mean_absolute_error: 0.0984\n",
      "Epoch 00013: val_loss improved from 0.07394 to 0.06870, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0984 - mean_absolute_error: 0.0984 - val_loss: 0.0687 - val_mean_absolute_error: 0.0687\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0993 - mean_absolute_error: 0.0993\n",
      "Epoch 00014: val_loss did not improve from 0.06870\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0993 - mean_absolute_error: 0.0993 - val_loss: 0.0747 - val_mean_absolute_error: 0.0747\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0981 - mean_absolute_error: 0.0981\n",
      "Epoch 00015: val_loss did not improve from 0.06870\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0981 - mean_absolute_error: 0.0981 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0992 - mean_absolute_error: 0.0992\n",
      "Epoch 00016: val_loss did not improve from 0.06870\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 00017: val_loss did not improve from 0.06870\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0980 - mean_absolute_error: 0.0980\n",
      "Epoch 00018: val_loss did not improve from 0.06870\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0980 - mean_absolute_error: 0.0980 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0987 - mean_absolute_error: 0.0987\n",
      "Epoch 00019: val_loss improved from 0.06870 to 0.06864, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0987 - mean_absolute_error: 0.0987 - val_loss: 0.0686 - val_mean_absolute_error: 0.0686\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0983 - mean_absolute_error: 0.0983\n",
      "Epoch 00020: val_loss did not improve from 0.06864\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0983 - mean_absolute_error: 0.0983 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 00021: val_loss did not improve from 0.06864\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00022: val_loss improved from 0.06864 to 0.06815, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0682 - val_mean_absolute_error: 0.0682\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0959 - mean_absolute_error: 0.0959\n",
      "Epoch 00023: val_loss did not improve from 0.06815\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0959 - mean_absolute_error: 0.0959 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00024: val_loss improved from 0.06815 to 0.06815, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0681 - val_mean_absolute_error: 0.0681\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00025: val_loss did not improve from 0.06815\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0963 - mean_absolute_error: 0.0963\n",
      "Epoch 00026: val_loss improved from 0.06815 to 0.06504, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.0650 - val_mean_absolute_error: 0.0650\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0947 - mean_absolute_error: 0.0947\n",
      "Epoch 00027: val_loss did not improve from 0.06504\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0944 - mean_absolute_error: 0.0944\n",
      "Epoch 00028: val_loss did not improve from 0.06504\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00029: val_loss improved from 0.06504 to 0.06464, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0646 - val_mean_absolute_error: 0.0646\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 00030: val_loss improved from 0.06464 to 0.06414, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.0641 - val_mean_absolute_error: 0.0641\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.0941\n",
      "Epoch 00031: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0941 - mean_absolute_error: 0.0941 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0947 - mean_absolute_error: 0.0947\n",
      "Epoch 00032: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.0942\n",
      "Epoch 00033: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.0655 - val_mean_absolute_error: 0.0655\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00034: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00035: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0650 - val_mean_absolute_error: 0.0650\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0930 - mean_absolute_error: 0.0930\n",
      "Epoch 00036: val_loss did not improve from 0.06414\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.0667 - val_mean_absolute_error: 0.0667\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0927 - mean_absolute_error: 0.0927\n",
      "Epoch 00037: val_loss improved from 0.06414 to 0.06302, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0927 - mean_absolute_error: 0.0927 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.0934\n",
      "Epoch 00038: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.0663 - val_mean_absolute_error: 0.0663\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0938 - mean_absolute_error: 0.0938\n",
      "Epoch 00039: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.0635 - val_mean_absolute_error: 0.0635\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.0933\n",
      "Epoch 00040: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0933 - mean_absolute_error: 0.0933 - val_loss: 0.0657 - val_mean_absolute_error: 0.0657\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.0937\n",
      "Epoch 00041: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.0932\n",
      "Epoch 00042: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.0644 - val_mean_absolute_error: 0.0644\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.0931\n",
      "Epoch 00043: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0931 - mean_absolute_error: 0.0931 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00044: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0686 - val_mean_absolute_error: 0.0686\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0950 - mean_absolute_error: 0.0950\n",
      "Epoch 00045: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0950 - mean_absolute_error: 0.0950 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.0933\n",
      "Epoch 00046: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0933 - mean_absolute_error: 0.0933 - val_loss: 0.0694 - val_mean_absolute_error: 0.0694\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0930 - mean_absolute_error: 0.0930\n",
      "Epoch 00047: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0925 - mean_absolute_error: 0.0925\n",
      "Epoch 00048: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.0686 - val_mean_absolute_error: 0.0686\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 00049: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.0678 - val_mean_absolute_error: 0.0678\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.0932\n",
      "Epoch 00050: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0927 - mean_absolute_error: 0.0927\n",
      "Epoch 00051: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0927 - mean_absolute_error: 0.0927 - val_loss: 0.0641 - val_mean_absolute_error: 0.0641\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 00052: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.0647 - val_mean_absolute_error: 0.0647\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 00053: val_loss did not improve from 0.06302\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.0641 - val_mean_absolute_error: 0.0641\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0928 - mean_absolute_error: 0.0928\n",
      "Epoch 00054: val_loss improved from 0.06302 to 0.06043, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0928 - mean_absolute_error: 0.0928 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00055: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0638 - val_mean_absolute_error: 0.0638\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00056: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0660 - val_mean_absolute_error: 0.0660\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 00057: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00058: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0663 - val_mean_absolute_error: 0.0663\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.0915\n",
      "Epoch 00059: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.0904\n",
      "Epoch 00060: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0904 - mean_absolute_error: 0.0904 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 00061: val_loss did not improve from 0.06043\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.0644 - val_mean_absolute_error: 0.0644\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0917 - mean_absolute_error: 0.0917\n",
      "Epoch 00062: val_loss improved from 0.06043 to 0.05984, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 00063: val_loss did not improve from 0.05984\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00064: val_loss improved from 0.05984 to 0.05975, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 00065: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0925 - mean_absolute_error: 0.0925\n",
      "Epoch 00066: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.0608 - val_mean_absolute_error: 0.0608\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.0908\n",
      "Epoch 00067: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0908 - mean_absolute_error: 0.0908 - val_loss: 0.0682 - val_mean_absolute_error: 0.0682\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00068: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 00069: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00070: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0918 - mean_absolute_error: 0.0918\n",
      "Epoch 00071: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0918 - mean_absolute_error: 0.0918 - val_loss: 0.0640 - val_mean_absolute_error: 0.0640\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0927 - mean_absolute_error: 0.0927\n",
      "Epoch 00072: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0927 - mean_absolute_error: 0.0927 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 00073: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00074: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00075: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0648 - val_mean_absolute_error: 0.0648\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.0915\n",
      "Epoch 00076: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.0660 - val_mean_absolute_error: 0.0660\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0917 - mean_absolute_error: 0.0917\n",
      "Epoch 00077: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.0675 - val_mean_absolute_error: 0.0675\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0912 - mean_absolute_error: 0.0912\n",
      "Epoch 00078: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.0666 - val_mean_absolute_error: 0.0666\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0913 - mean_absolute_error: 0.0913\n",
      "Epoch 00079: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0913 - mean_absolute_error: 0.0913 - val_loss: 0.0614 - val_mean_absolute_error: 0.0614\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0897 - mean_absolute_error: 0.0897\n",
      "Epoch 00080: val_loss did not improve from 0.05975\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0911 - mean_absolute_error: 0.0911\n",
      "Epoch 00081: val_loss improved from 0.05975 to 0.05721, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0912 - mean_absolute_error: 0.0912\n",
      "Epoch 00082: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.0904\n",
      "Epoch 00083: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0904 - mean_absolute_error: 0.0904 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0911 - mean_absolute_error: 0.0911\n",
      "Epoch 00084: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.0931\n",
      "Epoch 00085: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0931 - mean_absolute_error: 0.0931 - val_loss: 0.0655 - val_mean_absolute_error: 0.0655\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.0926\n",
      "Epoch 00086: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0926 - mean_absolute_error: 0.0926 - val_loss: 0.0744 - val_mean_absolute_error: 0.0744\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.0941\n",
      "Epoch 00087: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0941 - mean_absolute_error: 0.0941 - val_loss: 0.0691 - val_mean_absolute_error: 0.0691\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 00088: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 00089: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.0638 - val_mean_absolute_error: 0.0638\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.0926\n",
      "Epoch 00090: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0926 - mean_absolute_error: 0.0926 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.0899\n",
      "Epoch 00091: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0899 - mean_absolute_error: 0.0899 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.0899\n",
      "Epoch 00092: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0899 - mean_absolute_error: 0.0899 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.0892\n",
      "Epoch 00093: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0892 - mean_absolute_error: 0.0892 - val_loss: 0.0660 - val_mean_absolute_error: 0.0660\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00094: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.0889\n",
      "Epoch 00095: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0889 - mean_absolute_error: 0.0889 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0909 - mean_absolute_error: 0.0909\n",
      "Epoch 00096: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0909 - mean_absolute_error: 0.0909 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.0904\n",
      "Epoch 00097: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0904 - mean_absolute_error: 0.0904 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.0908\n",
      "Epoch 00098: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0908 - mean_absolute_error: 0.0908 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0909 - mean_absolute_error: 0.0909\n",
      "Epoch 00099: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0909 - mean_absolute_error: 0.0909 - val_loss: 0.0600 - val_mean_absolute_error: 0.0600\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00100: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0910 - mean_absolute_error: 0.0910\n",
      "Epoch 00101: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.0678 - val_mean_absolute_error: 0.0678\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0897 - mean_absolute_error: 0.0897\n",
      "Epoch 00102: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.0898\n",
      "Epoch 00103: val_loss did not improve from 0.05721\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.0640 - val_mean_absolute_error: 0.0640\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.0901\n",
      "Epoch 00104: val_loss improved from 0.05721 to 0.05496, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/4000/vgg19_angles_inner_6.h5\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0901 - mean_absolute_error: 0.0901 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 00105: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 00106: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 00107: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.0641 - val_mean_absolute_error: 0.0641\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 00108: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00109: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.0899\n",
      "Epoch 00110: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0899 - mean_absolute_error: 0.0899 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0895 - mean_absolute_error: 0.0895\n",
      "Epoch 00111: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0895 - mean_absolute_error: 0.0895 - val_loss: 0.0600 - val_mean_absolute_error: 0.0600\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0896 - mean_absolute_error: 0.0896\n",
      "Epoch 00112: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0896 - mean_absolute_error: 0.0896 - val_loss: 0.0662 - val_mean_absolute_error: 0.0662\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0896 - mean_absolute_error: 0.0896\n",
      "Epoch 00113: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0896 - mean_absolute_error: 0.0896 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00114: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.0898\n",
      "Epoch 00115: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.0616 - val_mean_absolute_error: 0.0616\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.0904\n",
      "Epoch 00116: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0904 - mean_absolute_error: 0.0904 - val_loss: 0.0646 - val_mean_absolute_error: 0.0646\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0903 - mean_absolute_error: 0.0903\n",
      "Epoch 00117: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0903 - mean_absolute_error: 0.0903 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0903 - mean_absolute_error: 0.0903\n",
      "Epoch 00118: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0903 - mean_absolute_error: 0.0903 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00119: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.0892\n",
      "Epoch 00120: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0892 - mean_absolute_error: 0.0892 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0887 - mean_absolute_error: 0.0887\n",
      "Epoch 00121: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0887 - mean_absolute_error: 0.0887 - val_loss: 0.0603 - val_mean_absolute_error: 0.0603\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00122: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0910 - mean_absolute_error: 0.0910\n",
      "Epoch 00123: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.0889\n",
      "Epoch 00124: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0889 - mean_absolute_error: 0.0889 - val_loss: 0.0653 - val_mean_absolute_error: 0.0653\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00125: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.0901\n",
      "Epoch 00126: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0901 - mean_absolute_error: 0.0901 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 00127: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.0684 - val_mean_absolute_error: 0.0684\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0928 - mean_absolute_error: 0.0928\n",
      "Epoch 00128: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0928 - mean_absolute_error: 0.0928 - val_loss: 0.0615 - val_mean_absolute_error: 0.0615\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0910 - mean_absolute_error: 0.0910\n",
      "Epoch 00129: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.0652 - val_mean_absolute_error: 0.0652\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00130: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0657 - val_mean_absolute_error: 0.0657\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0895 - mean_absolute_error: 0.0895\n",
      "Epoch 00131: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0895 - mean_absolute_error: 0.0895 - val_loss: 0.0626 - val_mean_absolute_error: 0.0626\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0900 - mean_absolute_error: 0.0900\n",
      "Epoch 00132: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.0900 - mean_absolute_error: 0.0900 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 00133: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.0595 - val_mean_absolute_error: 0.0595\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0902 - mean_absolute_error: 0.0902\n",
      "Epoch 00134: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0902 - mean_absolute_error: 0.0902 - val_loss: 0.0614 - val_mean_absolute_error: 0.0614\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00135: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00136: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 00137: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.0635 - val_mean_absolute_error: 0.0635\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0902 - mean_absolute_error: 0.0902\n",
      "Epoch 00138: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0902 - mean_absolute_error: 0.0902 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.0889\n",
      "Epoch 00139: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0889 - mean_absolute_error: 0.0889 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.0906\n",
      "Epoch 00140: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0900 - mean_absolute_error: 0.0900\n",
      "Epoch 00141: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0900 - mean_absolute_error: 0.0900 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00142: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0883 - mean_absolute_error: 0.0883\n",
      "Epoch 00143: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0883 - mean_absolute_error: 0.0883 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.0892\n",
      "Epoch 00144: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0892 - mean_absolute_error: 0.0892 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0885 - mean_absolute_error: 0.0885\n",
      "Epoch 00145: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0885 - mean_absolute_error: 0.0885 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 00146: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.0595 - val_mean_absolute_error: 0.0595\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.0892\n",
      "Epoch 00147: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0892 - mean_absolute_error: 0.0892 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 00148: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0887 - mean_absolute_error: 0.0887\n",
      "Epoch 00149: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0887 - mean_absolute_error: 0.0887 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0882 - mean_absolute_error: 0.0882\n",
      "Epoch 00150: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0882 - mean_absolute_error: 0.0882 - val_loss: 0.0659 - val_mean_absolute_error: 0.0659\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.0898\n",
      "Epoch 00151: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.0901\n",
      "Epoch 00152: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0901 - mean_absolute_error: 0.0901 - val_loss: 0.0628 - val_mean_absolute_error: 0.0628\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0896 - mean_absolute_error: 0.0896\n",
      "Epoch 00153: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0896 - mean_absolute_error: 0.0896 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 00154: val_loss did not improve from 0.05496\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 00154: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = dict()\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    model_path = os.path.join(save_models_path, 'vgg19_angles_inner_'+str(i)+'.h5')\n",
    "    mc[i] = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 1000\n",
    "history = {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    print('Model for ', i, ' angles')\n",
    "    history[i] = models_ai[i].fit(training_generator[i],\n",
    "                            validation_data = validation_generator[i],\n",
    "                            epochs = epochs,\n",
    "                            steps_per_epoch = len(training_generator[i]),\n",
    "                            validation_steps = len(validation_generator[i]),\n",
    "                            callbacks=[es, mc[i]]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 15))\n",
    "for i in range(5):\n",
    "    fig.add_subplot(3, 2, i+1)\n",
    "    plt.plot(history[i+2].history['loss'])\n",
    "    plt.plot(history[i+2].history['val_loss'])\n",
    "    plt.title('Model loss '+str(i+2))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
