{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorflow\n",
    "import tensorflow as tf\n",
    "# Below command is to avoid the known bug which prevents computation on some GPU devices\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# Load preprocessing tools\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from PIL import Image\n",
    "# Load model building blocks\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Load pre-trained model library\n",
    "from tensorflow.keras import applications\n",
    "# Load miscelaneous libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'image_data', 'small', '400', 'train')\n",
    "val_image_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'image_data', 'small', '400', 'val')\n",
    "train_labels_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'labels', 'small', '400', 'train')\n",
    "val_labels_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'labels', 'small', '400', 'val')\n",
    "load_models_path = os.path.join('/home', 'renat_sergazinov', 'python-git-workspace', \n",
    "                               'PhotoForceReconML', 'models')\n",
    "save_models_path = os.path.join('/home', 'renat_sergazinov', \n",
    "                          'python-git-workspace', 'PhotoForceReconML', 'models', 'small', '400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the directory. The data are the images of particles split into subdirectories based on the number of forces acting on the particle. The labels should be loaded from a separate directory. Each label corresponds to two particles. \n",
    "\n",
    "The size of all images is adjusted so that all images are 128*128 using nearest neighbor interpolation. Validation split is performed: 20% is set aside for validation. Additionally images are blurred using Gaussian blur with kernel radius = 1.The pixel values are scaled using 1/255 to be in the interval [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian blur class\n",
    "class GaussBlur:\n",
    "    def __init__(self, radius):\n",
    "        self.radius = radius\n",
    "    def blur(self, image):\n",
    "        return gaussian_filter(image, sigma = self.radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for data generation\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_image_paths = None, labels = None,  \n",
    "                 batch_size = 32, dim = None, n_channels = 3, rescale = 1, \n",
    "                 shuffle=True, save_dir = None, preprocessing_func = None):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_image_paths = list_image_paths\n",
    "        self.n_channels = n_channels\n",
    "        self.rescale = rescale\n",
    "        self.shuffle = shuffle\n",
    "        self.save_dir = save_dir\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indices)\n",
    "        \n",
    "        if self.save_dir is not None:\n",
    "            for i in range(X.shape[0]):\n",
    "                path = os.path.join(self.save_dir, 'img' + str(i) + '.jpg')\n",
    "                plt.imsave(path, np.asarray(X[i, ]), vmin = 0, vmax = 1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indices = np.arange(len(self.list_image_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, indices):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        \n",
    "        # Initialisation\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        list_image_paths_batch = [self.list_image_paths[k] for k in indices]\n",
    "        \n",
    "        # Get labels\n",
    "        y = np.array([self.labels[k, :] for k in indices])\n",
    "        \n",
    "        # Generate data\n",
    "        for i, image_path in enumerate(list_image_paths_batch):\n",
    "            # Load image and transform\n",
    "            image = Image.open(os.path.join(image_path))\n",
    "            if self.dim is not None:\n",
    "                image = image.resize(self.dim, resample = Image.NEAREST)\n",
    "            image = np.array(image)[:, :, :self.n_channels]\n",
    "            image = image * self.rescale\n",
    "            if self.preprocessing_func is not None:\n",
    "                image = self.preprocessing_func(image)\n",
    "            # Store sample\n",
    "            X[i,] = image\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sorter of image names in order by image number (default is alphanumric)\n",
    "def sorter(item):\n",
    "    # Since highest marks first, least error = most marks\n",
    "    radius = float(item[1 : item.find('_')])\n",
    "    num_img = int(item[item.find('g') + 1 : item.find('j') - 1])\n",
    "    return (radius, num_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and validation sets\n",
    "\n",
    "X_train, X_val = {}, {}\n",
    "y_train, y_val = {}, {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    X_path_train = os.path.join(train_image_path, str(i))\n",
    "    X_path_val = os.path.join(val_image_path, str(i))\n",
    "    X_train[i] = [os.path.join(X_path_train, name) for name in sorted(os.listdir(X_path_train), key = sorter)]\n",
    "    X_val[i] = [os.path.join(X_path_val, name) for name in sorted(os.listdir(X_path_val), key = sorter)]\n",
    "    y_train[i] = np.load(os.path.join(train_labels_path, str(i), 'mags.npy'))\n",
    "    y_val[i] = np.load(os.path.join(val_labels_path, str(i), 'mags.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data generators\n",
    "gaussblur = GaussBlur(1)\n",
    "params = {'batch_size': 32, \n",
    "          'dim': (128, 128), \n",
    "          'n_channels': 3, \n",
    "          'rescale': 1 / 255, \n",
    "          'shuffle': True, \n",
    "          'save_dir': None,\n",
    "          'preprocessing_func': gaussblur.blur\n",
    "          }\n",
    "\n",
    "training_generator = {}\n",
    "validation_generator = {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    training_generator[i] = DataGenerator(X_train[i], y_train[i], **params)\n",
    "    validation_generator[i] = DataGenerator(X_val[i], y_val[i], **params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InceptionResNetV2 Models Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks is defined and compiled in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models_m = dict()                         \n",
    "for k in range(5):\n",
    "     i = k + 2\n",
    "     models_m[i] = load_model(os.path.join(load_models_path, 'InceptionResNetV2_mags_'+str(i)+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 55,912,674\n",
      "Trainable params: 55,852,130\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 55,913,699\n",
      "Trainable params: 55,853,155\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 55,914,724\n",
      "Trainable params: 55,854,180\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 55,915,749\n",
      "Trainable params: 55,855,205\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 55,916,774\n",
      "Trainable params: 55,856,230\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    models_m[i].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    i = 2 + k\n",
    "    models_m[i].compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = dict()\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    model_path = os.path.join(save_models_path, 'InceptionResNetV2_mags_'+str(i)+'.h5')\n",
    "    mc[i] = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for  2  angles\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2287 - mean_absolute_error: 0.2287\n",
      "Epoch 00001: val_loss improved from inf to 0.20252, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 5s 475ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2025 - val_mean_absolute_error: 0.2025\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1756 - mean_absolute_error: 0.1756\n",
      "Epoch 00002: val_loss improved from 0.20252 to 0.15576, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1756 - mean_absolute_error: 0.1756 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1327 - mean_absolute_error: 0.1327\n",
      "Epoch 00003: val_loss improved from 0.15576 to 0.09629, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.1327 - mean_absolute_error: 0.1327 - val_loss: 0.0963 - val_mean_absolute_error: 0.0963\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.0915\n",
      "Epoch 00004: val_loss improved from 0.09629 to 0.06133, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.0624\n",
      "Epoch 00005: val_loss improved from 0.06133 to 0.04368, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0624 - mean_absolute_error: 0.0624 - val_loss: 0.0437 - val_mean_absolute_error: 0.0437\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.0456\n",
      "Epoch 00006: val_loss improved from 0.04368 to 0.03884, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0456 - mean_absolute_error: 0.0456 - val_loss: 0.0388 - val_mean_absolute_error: 0.0388\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0370 - mean_absolute_error: 0.0370\n",
      "Epoch 00007: val_loss did not improve from 0.03884\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0370 - mean_absolute_error: 0.0370 - val_loss: 0.0406 - val_mean_absolute_error: 0.0406\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.0302\n",
      "Epoch 00008: val_loss improved from 0.03884 to 0.03339, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0302 - mean_absolute_error: 0.0302 - val_loss: 0.0334 - val_mean_absolute_error: 0.0334\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.0282\n",
      "Epoch 00009: val_loss improved from 0.03339 to 0.03028, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0262\n",
      "Epoch 00010: val_loss improved from 0.03028 to 0.02419, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0262 - mean_absolute_error: 0.0262 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.0257\n",
      "Epoch 00011: val_loss improved from 0.02419 to 0.02255, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.0257 - mean_absolute_error: 0.0257 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0244\n",
      "Epoch 00012: val_loss improved from 0.02255 to 0.01844, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.0244 - mean_absolute_error: 0.0244 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0237\n",
      "Epoch 00013: val_loss did not improve from 0.01844\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0237 - mean_absolute_error: 0.0237 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0211 - mean_absolute_error: 0.0211\n",
      "Epoch 00014: val_loss did not improve from 0.01844\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.0232\n",
      "Epoch 00015: val_loss improved from 0.01844 to 0.01635, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0232 - mean_absolute_error: 0.0232 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00016: val_loss improved from 0.01635 to 0.01575, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0204 - mean_absolute_error: 0.0204\n",
      "Epoch 00017: val_loss did not improve from 0.01575\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0204 - mean_absolute_error: 0.0204 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0212 - mean_absolute_error: 0.0212\n",
      "Epoch 00018: val_loss improved from 0.01575 to 0.01504, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0212 - mean_absolute_error: 0.0212\n",
      "Epoch 00019: val_loss improved from 0.01504 to 0.01317, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0229 - mean_absolute_error: 0.0229\n",
      "Epoch 00020: val_loss did not improve from 0.01317\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0229 - mean_absolute_error: 0.0229 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0213 - mean_absolute_error: 0.0213\n",
      "Epoch 00021: val_loss did not improve from 0.01317\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0213 - mean_absolute_error: 0.0213 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.0201\n",
      "Epoch 00022: val_loss did not improve from 0.01317\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0212 - mean_absolute_error: 0.0212\n",
      "Epoch 00023: val_loss did not improve from 0.01317\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0178 - val_mean_absolute_error: 0.0178\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.0188\n",
      "Epoch 00024: val_loss improved from 0.01317 to 0.01314, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0215 - mean_absolute_error: 0.0215\n",
      "Epoch 00025: val_loss did not improve from 0.01314\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0215 - mean_absolute_error: 0.0215 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0200\n",
      "Epoch 00026: val_loss did not improve from 0.01314\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0200 - mean_absolute_error: 0.0200 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0206 - mean_absolute_error: 0.0206\n",
      "Epoch 00027: val_loss improved from 0.01314 to 0.01288, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0206 - mean_absolute_error: 0.0206 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0204 - mean_absolute_error: 0.0204\n",
      "Epoch 00028: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0204 - mean_absolute_error: 0.0204 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 00029: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.0177\n",
      "Epoch 00030: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0204 - mean_absolute_error: 0.0204\n",
      "Epoch 00031: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0204 - mean_absolute_error: 0.0204 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00032: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00033: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0198 - mean_absolute_error: 0.0198\n",
      "Epoch 00034: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_absolute_error: 0.0208\n",
      "Epoch 00035: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0208 - mean_absolute_error: 0.0208 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0202 - mean_absolute_error: 0.0202\n",
      "Epoch 00036: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00037: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 00038: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.0205\n",
      "Epoch 00039: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.0201\n",
      "Epoch 00040: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00041: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.0193\n",
      "Epoch 00042: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.0201\n",
      "Epoch 00043: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00044: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0202 - mean_absolute_error: 0.0202\n",
      "Epoch 00045: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.0205\n",
      "Epoch 00046: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00047: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00048: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0202 - mean_absolute_error: 0.0202\n",
      "Epoch 00049: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.0179\n",
      "Epoch 00050: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00051: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00052: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.0223\n",
      "Epoch 00053: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0223 - mean_absolute_error: 0.0223 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00054: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0197 - mean_absolute_error: 0.0197\n",
      "Epoch 00055: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00056: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0200\n",
      "Epoch 00057: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0200 - mean_absolute_error: 0.0200 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 00058: val_loss did not improve from 0.01288\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00059: val_loss improved from 0.01288 to 0.01212, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00060: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0200\n",
      "Epoch 00061: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0200 - mean_absolute_error: 0.0200 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0206 - mean_absolute_error: 0.0206\n",
      "Epoch 00062: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0206 - mean_absolute_error: 0.0206 - val_loss: 0.0142 - val_mean_absolute_error: 0.0142\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0172\n",
      "Epoch 00063: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00064: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0209\n",
      "Epoch 00065: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00066: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 00067: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0198 - mean_absolute_error: 0.0198\n",
      "Epoch 00068: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00069: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00070: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00071: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00072: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00073: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0219 - mean_absolute_error: 0.0219\n",
      "Epoch 00074: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0219 - mean_absolute_error: 0.0219 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0198 - mean_absolute_error: 0.0198\n",
      "Epoch 00075: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00076: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0197 - mean_absolute_error: 0.0197\n",
      "Epoch 00077: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0136 - val_mean_absolute_error: 0.0136\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00078: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.0193\n",
      "Epoch 00079: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0142 - val_mean_absolute_error: 0.0142\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00080: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.0177\n",
      "Epoch 00081: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0194 - mean_absolute_error: 0.0194\n",
      "Epoch 00082: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 00083: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0128 - val_mean_absolute_error: 0.0128\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00084: val_loss did not improve from 0.01212\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.0195\n",
      "Epoch 00085: val_loss improved from 0.01212 to 0.01166, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00086: val_loss did not improve from 0.01166\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00087: val_loss did not improve from 0.01166\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 00088: val_loss did not improve from 0.01166\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.0190\n",
      "Epoch 00089: val_loss improved from 0.01166 to 0.01108, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.0192\n",
      "Epoch 00090: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00091: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.0179\n",
      "Epoch 00092: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0209\n",
      "Epoch 00093: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00094: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00095: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00096: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 00097: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.0188\n",
      "Epoch 00098: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.0192\n",
      "Epoch 00099: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00100: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.0179\n",
      "Epoch 00101: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.0192\n",
      "Epoch 00102: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00103: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0196 - mean_absolute_error: 0.0196\n",
      "Epoch 00104: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0196 - mean_absolute_error: 0.0196 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00105: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 00106: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00107: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00108: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0203\n",
      "Epoch 00109: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.0193\n",
      "Epoch 00110: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00111: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0182 - mean_absolute_error: 0.0182\n",
      "Epoch 00112: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00113: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0182 - mean_absolute_error: 0.0182\n",
      "Epoch 00114: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00115: val_loss did not improve from 0.01108\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 00116: val_loss improved from 0.01108 to 0.01082, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_2.h5\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00117: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00118: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00119: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0173 - mean_absolute_error: 0.0173\n",
      "Epoch 00120: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0173 - mean_absolute_error: 0.0173\n",
      "Epoch 00121: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00122: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0114 - val_mean_absolute_error: 0.0114\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00123: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0136 - val_mean_absolute_error: 0.0136\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00124: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.0179\n",
      "Epoch 00125: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.0188\n",
      "Epoch 00126: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00127: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.0190\n",
      "Epoch 00128: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 00129: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.0190\n",
      "Epoch 00130: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00131: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0148 - val_mean_absolute_error: 0.0148\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00132: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0209\n",
      "Epoch 00133: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0200\n",
      "Epoch 00134: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0200 - mean_absolute_error: 0.0200 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00135: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00136: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0209\n",
      "Epoch 00137: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00138: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 00139: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.0199\n",
      "Epoch 00140: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00141: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.0201\n",
      "Epoch 00142: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0128 - val_mean_absolute_error: 0.0128\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.0207\n",
      "Epoch 00143: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0207 - mean_absolute_error: 0.0207 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00144: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.0190\n",
      "Epoch 00145: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00146: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00147: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0167 - mean_absolute_error: 0.0167\n",
      "Epoch 00148: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00149: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0145 - val_mean_absolute_error: 0.0145\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 00150: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 00151: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.0177\n",
      "Epoch 00152: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 00153: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.0185\n",
      "Epoch 00154: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0209\n",
      "Epoch 00155: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 00156: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.0192\n",
      "Epoch 00157: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 00158: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0176 - mean_absolute_error: 0.0176\n",
      "Epoch 00159: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0200\n",
      "Epoch 00160: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0200 - mean_absolute_error: 0.0200 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.0188\n",
      "Epoch 00161: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 00162: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.0175\n",
      "Epoch 00163: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 00164: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.0190\n",
      "Epoch 00165: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.0188\n",
      "Epoch 00166: val_loss did not improve from 0.01082\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 00166: early stopping\n",
      "Model for  3  angles\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2085 - mean_absolute_error: 0.2085\n",
      "Epoch 00001: val_loss improved from inf to 0.15083, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.2085 - mean_absolute_error: 0.2085 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1627 - mean_absolute_error: 0.1627\n",
      "Epoch 00002: val_loss improved from 0.15083 to 0.10380, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.1627 - mean_absolute_error: 0.1627 - val_loss: 0.1038 - val_mean_absolute_error: 0.1038\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1347 - mean_absolute_error: 0.1347\n",
      "Epoch 00003: val_loss improved from 0.10380 to 0.07917, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.0792 - val_mean_absolute_error: 0.0792\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.1132\n",
      "Epoch 00004: val_loss improved from 0.07917 to 0.05971, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0992 - mean_absolute_error: 0.0992\n",
      "Epoch 00005: val_loss improved from 0.05971 to 0.04359, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.0436 - val_mean_absolute_error: 0.0436\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0917 - mean_absolute_error: 0.0917\n",
      "Epoch 00006: val_loss improved from 0.04359 to 0.03202, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0841 - mean_absolute_error: 0.0841\n",
      "Epoch 00007: val_loss improved from 0.03202 to 0.02849, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0852 - mean_absolute_error: 0.0852\n",
      "Epoch 00008: val_loss improved from 0.02849 to 0.02550, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0852 - mean_absolute_error: 0.0852 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0791 - mean_absolute_error: 0.0791\n",
      "Epoch 00009: val_loss improved from 0.02550 to 0.02035, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0791 - mean_absolute_error: 0.0791 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.0731\n",
      "Epoch 00010: val_loss improved from 0.02035 to 0.01832, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0833 - mean_absolute_error: 0.0833\n",
      "Epoch 00011: val_loss improved from 0.01832 to 0.01766, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0756 - mean_absolute_error: 0.0756\n",
      "Epoch 00012: val_loss did not improve from 0.01766\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0756 - mean_absolute_error: 0.0756 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0716 - mean_absolute_error: 0.0716\n",
      "Epoch 00013: val_loss improved from 0.01766 to 0.01636, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.0716 - mean_absolute_error: 0.0716 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0710 - mean_absolute_error: 0.0710\n",
      "Epoch 00014: val_loss improved from 0.01636 to 0.01597, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0710 - mean_absolute_error: 0.0710 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.0712\n",
      "Epoch 00015: val_loss did not improve from 0.01597\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0712 - mean_absolute_error: 0.0712 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.0673\n",
      "Epoch 00016: val_loss improved from 0.01597 to 0.01575, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.0671\n",
      "Epoch 00017: val_loss improved from 0.01575 to 0.01551, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.0676\n",
      "Epoch 00018: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0676 - mean_absolute_error: 0.0676 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0695 - mean_absolute_error: 0.0695\n",
      "Epoch 00019: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0695 - mean_absolute_error: 0.0695 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.0660\n",
      "Epoch 00020: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0660 - mean_absolute_error: 0.0660 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0686 - mean_absolute_error: 0.0686\n",
      "Epoch 00021: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0643 - mean_absolute_error: 0.0643\n",
      "Epoch 00022: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0643 - mean_absolute_error: 0.0643 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0640 - mean_absolute_error: 0.0640\n",
      "Epoch 00023: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0640 - mean_absolute_error: 0.0640 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0623 - mean_absolute_error: 0.0623\n",
      "Epoch 00024: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0623 - mean_absolute_error: 0.0623 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0642 - mean_absolute_error: 0.0642\n",
      "Epoch 00025: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0642 - mean_absolute_error: 0.0642 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0585 - mean_absolute_error: 0.0585\n",
      "Epoch 00026: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0585 - mean_absolute_error: 0.0585 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0629 - mean_absolute_error: 0.0629\n",
      "Epoch 00027: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0629 - mean_absolute_error: 0.0629 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0611 - mean_absolute_error: 0.0611\n",
      "Epoch 00028: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0611 - mean_absolute_error: 0.0611 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.0624\n",
      "Epoch 00029: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0624 - mean_absolute_error: 0.0624 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0616 - mean_absolute_error: 0.0616\n",
      "Epoch 00030: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0616 - mean_absolute_error: 0.0616 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0592 - mean_absolute_error: 0.0592\n",
      "Epoch 00031: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0592 - mean_absolute_error: 0.0592 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0573 - mean_absolute_error: 0.0573\n",
      "Epoch 00032: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0573 - mean_absolute_error: 0.0573 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_absolute_error: 0.0605\n",
      "Epoch 00033: val_loss did not improve from 0.01551\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0605 - mean_absolute_error: 0.0605 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0612 - mean_absolute_error: 0.0612\n",
      "Epoch 00034: val_loss improved from 0.01551 to 0.01549, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0612 - mean_absolute_error: 0.0612 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0601 - mean_absolute_error: 0.0601\n",
      "Epoch 00035: val_loss did not improve from 0.01549\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0601 - mean_absolute_error: 0.0601 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0583 - mean_absolute_error: 0.0583\n",
      "Epoch 00036: val_loss did not improve from 0.01549\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0583 - mean_absolute_error: 0.0583 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0584 - mean_absolute_error: 0.0584\n",
      "Epoch 00037: val_loss did not improve from 0.01549\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0584 - mean_absolute_error: 0.0584 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0609 - mean_absolute_error: 0.0609\n",
      "Epoch 00038: val_loss improved from 0.01549 to 0.01513, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0609 - mean_absolute_error: 0.0609 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0612 - mean_absolute_error: 0.0612\n",
      "Epoch 00039: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0612 - mean_absolute_error: 0.0612 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0591 - mean_absolute_error: 0.0591\n",
      "Epoch 00040: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0591 - mean_absolute_error: 0.0591 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0602 - mean_absolute_error: 0.0602\n",
      "Epoch 00041: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0602 - mean_absolute_error: 0.0602 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0574 - mean_absolute_error: 0.0574\n",
      "Epoch 00042: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0574 - mean_absolute_error: 0.0574 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0610 - mean_absolute_error: 0.0610\n",
      "Epoch 00043: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0610 - mean_absolute_error: 0.0610 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0576 - mean_absolute_error: 0.0576\n",
      "Epoch 00044: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0576 - mean_absolute_error: 0.0576 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0537 - mean_absolute_error: 0.0537\n",
      "Epoch 00045: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0537 - mean_absolute_error: 0.0537 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0587 - mean_absolute_error: 0.0587\n",
      "Epoch 00046: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0587 - mean_absolute_error: 0.0587 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0559 - mean_absolute_error: 0.0559\n",
      "Epoch 00047: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0559 - mean_absolute_error: 0.0559 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0590 - mean_absolute_error: 0.0590\n",
      "Epoch 00048: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0590 - mean_absolute_error: 0.0590 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0563 - mean_absolute_error: 0.0563\n",
      "Epoch 00049: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0563 - mean_absolute_error: 0.0563 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0560 - mean_absolute_error: 0.0560\n",
      "Epoch 00050: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0560 - mean_absolute_error: 0.0560 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0565 - mean_absolute_error: 0.0565\n",
      "Epoch 00051: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0565 - mean_absolute_error: 0.0565 - val_loss: 0.0176 - val_mean_absolute_error: 0.0176\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0562 - mean_absolute_error: 0.0562\n",
      "Epoch 00052: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0562 - mean_absolute_error: 0.0562 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0599 - mean_absolute_error: 0.0599\n",
      "Epoch 00053: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0599 - mean_absolute_error: 0.0599 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_absolute_error: 0.0557\n",
      "Epoch 00054: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0557 - mean_absolute_error: 0.0557 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0589 - mean_absolute_error: 0.0589\n",
      "Epoch 00055: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0589 - mean_absolute_error: 0.0589 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.0578\n",
      "Epoch 00056: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0578 - mean_absolute_error: 0.0578 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_absolute_error: 0.0549\n",
      "Epoch 00057: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0549 - mean_absolute_error: 0.0549 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.0550\n",
      "Epoch 00058: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0550 - mean_absolute_error: 0.0550 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0505 - mean_absolute_error: 0.0505\n",
      "Epoch 00059: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0505 - mean_absolute_error: 0.0505 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0560 - mean_absolute_error: 0.0560\n",
      "Epoch 00060: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0560 - mean_absolute_error: 0.0560 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0538 - mean_absolute_error: 0.0538\n",
      "Epoch 00061: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0538 - mean_absolute_error: 0.0538 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0521 - mean_absolute_error: 0.0521\n",
      "Epoch 00062: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0521 - mean_absolute_error: 0.0521 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0584 - mean_absolute_error: 0.0584\n",
      "Epoch 00063: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0584 - mean_absolute_error: 0.0584 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0562 - mean_absolute_error: 0.0562\n",
      "Epoch 00064: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0562 - mean_absolute_error: 0.0562 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0538 - mean_absolute_error: 0.0538\n",
      "Epoch 00065: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0538 - mean_absolute_error: 0.0538 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0536 - mean_absolute_error: 0.0536\n",
      "Epoch 00066: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0536 - mean_absolute_error: 0.0536 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00067: val_loss did not improve from 0.01513\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0546 - mean_absolute_error: 0.0546\n",
      "Epoch 00068: val_loss improved from 0.01513 to 0.01457, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0546 - mean_absolute_error: 0.0546 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0532 - mean_absolute_error: 0.0532\n",
      "Epoch 00069: val_loss did not improve from 0.01457\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0532 - mean_absolute_error: 0.0532 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0559 - mean_absolute_error: 0.0559\n",
      "Epoch 00070: val_loss did not improve from 0.01457\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0559 - mean_absolute_error: 0.0559 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_absolute_error: 0.0548\n",
      "Epoch 00071: val_loss improved from 0.01457 to 0.01405, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_3.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0531 - mean_absolute_error: 0.0531\n",
      "Epoch 00072: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0531 - mean_absolute_error: 0.0531 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0537 - mean_absolute_error: 0.0537\n",
      "Epoch 00073: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0537 - mean_absolute_error: 0.0537 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00074: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.0485\n",
      "Epoch 00075: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0485 - mean_absolute_error: 0.0485 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0577 - mean_absolute_error: 0.0577\n",
      "Epoch 00076: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0577 - mean_absolute_error: 0.0577 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0568 - mean_absolute_error: 0.0568\n",
      "Epoch 00077: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0568 - mean_absolute_error: 0.0568 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0561 - mean_absolute_error: 0.0561\n",
      "Epoch 00078: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0561 - mean_absolute_error: 0.0561 - val_loss: 0.0178 - val_mean_absolute_error: 0.0178\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0561 - mean_absolute_error: 0.0561\n",
      "Epoch 00079: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0561 - mean_absolute_error: 0.0561 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0573 - mean_absolute_error: 0.0573\n",
      "Epoch 00080: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0573 - mean_absolute_error: 0.0573 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0572 - mean_absolute_error: 0.0572\n",
      "Epoch 00081: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0572 - mean_absolute_error: 0.0572 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0532 - mean_absolute_error: 0.0532\n",
      "Epoch 00082: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0532 - mean_absolute_error: 0.0532 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00083: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.0553\n",
      "Epoch 00084: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0553 - mean_absolute_error: 0.0553 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00085: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0513 - mean_absolute_error: 0.0513\n",
      "Epoch 00086: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0542 - mean_absolute_error: 0.0542\n",
      "Epoch 00087: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0542 - mean_absolute_error: 0.0542 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0544 - mean_absolute_error: 0.0544\n",
      "Epoch 00088: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0544 - mean_absolute_error: 0.0544 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_absolute_error: 0.0530\n",
      "Epoch 00089: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0530 - mean_absolute_error: 0.0530 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0547 - mean_absolute_error: 0.0547\n",
      "Epoch 00090: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0547 - mean_absolute_error: 0.0547 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0534 - mean_absolute_error: 0.0534\n",
      "Epoch 00091: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00092: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.0553\n",
      "Epoch 00093: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0553 - mean_absolute_error: 0.0553 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00094: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0538 - mean_absolute_error: 0.0538\n",
      "Epoch 00095: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0538 - mean_absolute_error: 0.0538 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00096: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.0539\n",
      "Epoch 00097: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_absolute_error: 0.0557\n",
      "Epoch 00098: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0557 - mean_absolute_error: 0.0557 - val_loss: 0.0176 - val_mean_absolute_error: 0.0176\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_absolute_error: 0.0557\n",
      "Epoch 00099: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0557 - mean_absolute_error: 0.0557 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00100: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0532 - mean_absolute_error: 0.0532\n",
      "Epoch 00101: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0532 - mean_absolute_error: 0.0532 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.0497\n",
      "Epoch 00102: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0497 - mean_absolute_error: 0.0497 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.0539\n",
      "Epoch 00103: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0476 - mean_absolute_error: 0.0476\n",
      "Epoch 00104: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0476 - mean_absolute_error: 0.0476 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0534 - mean_absolute_error: 0.0534\n",
      "Epoch 00105: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0496 - mean_absolute_error: 0.0496\n",
      "Epoch 00106: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0496 - mean_absolute_error: 0.0496 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0512 - mean_absolute_error: 0.0512\n",
      "Epoch 00107: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0512 - mean_absolute_error: 0.0512 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0501 - mean_absolute_error: 0.0501\n",
      "Epoch 00108: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0501 - mean_absolute_error: 0.0501 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0526 - mean_absolute_error: 0.0526\n",
      "Epoch 00109: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0526 - mean_absolute_error: 0.0526 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0528 - mean_absolute_error: 0.0528\n",
      "Epoch 00110: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0528 - mean_absolute_error: 0.0528 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00111: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0507 - mean_absolute_error: 0.0507\n",
      "Epoch 00112: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0507 - mean_absolute_error: 0.0507 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0534 - mean_absolute_error: 0.0534\n",
      "Epoch 00113: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.0498\n",
      "Epoch 00114: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0498 - mean_absolute_error: 0.0498 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.0553\n",
      "Epoch 00115: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0553 - mean_absolute_error: 0.0553 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0475 - mean_absolute_error: 0.0475\n",
      "Epoch 00116: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0475 - mean_absolute_error: 0.0475 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.0494\n",
      "Epoch 00117: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0494 - mean_absolute_error: 0.0494 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.0479\n",
      "Epoch 00118: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0479 - mean_absolute_error: 0.0479 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00119: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.0529\n",
      "Epoch 00120: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.0494\n",
      "Epoch 00121: val_loss did not improve from 0.01405\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0494 - mean_absolute_error: 0.0494 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 00121: early stopping\n",
      "Model for  4  angles\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2342 - mean_absolute_error: 0.2342\n",
      "Epoch 00001: val_loss improved from inf to 0.15929, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.2342 - mean_absolute_error: 0.2342 - val_loss: 0.1593 - val_mean_absolute_error: 0.1593\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1618 - mean_absolute_error: 0.1618\n",
      "Epoch 00002: val_loss improved from 0.15929 to 0.11026, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1618 - mean_absolute_error: 0.1618 - val_loss: 0.1103 - val_mean_absolute_error: 0.1103\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1077 - mean_absolute_error: 0.1077\n",
      "Epoch 00003: val_loss improved from 0.11026 to 0.07342, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1077 - mean_absolute_error: 0.1077 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0844 - mean_absolute_error: 0.0844\n",
      "Epoch 00004: val_loss improved from 0.07342 to 0.04638, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0464 - val_mean_absolute_error: 0.0464\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.0725\n",
      "Epoch 00005: val_loss improved from 0.04638 to 0.03522, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.0690\n",
      "Epoch 00006: val_loss improved from 0.03522 to 0.03336, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0334 - val_mean_absolute_error: 0.0334\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.0690\n",
      "Epoch 00007: val_loss improved from 0.03336 to 0.03072, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.0678\n",
      "Epoch 00008: val_loss improved from 0.03072 to 0.03064, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.0678 - mean_absolute_error: 0.0678 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.0660\n",
      "Epoch 00009: val_loss did not improve from 0.03064\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0660 - mean_absolute_error: 0.0660 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.0668\n",
      "Epoch 00010: val_loss improved from 0.03064 to 0.02918, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0668 - mean_absolute_error: 0.0668 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0666 - mean_absolute_error: 0.0666\n",
      "Epoch 00011: val_loss did not improve from 0.02918\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0666 - mean_absolute_error: 0.0666 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0629 - mean_absolute_error: 0.0629\n",
      "Epoch 00012: val_loss did not improve from 0.02918\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0629 - mean_absolute_error: 0.0629 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0630 - mean_absolute_error: 0.0630\n",
      "Epoch 00013: val_loss improved from 0.02918 to 0.02893, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0630 - mean_absolute_error: 0.0630 - val_loss: 0.0289 - val_mean_absolute_error: 0.0289\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.0654\n",
      "Epoch 00014: val_loss improved from 0.02893 to 0.02725, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0654 - mean_absolute_error: 0.0654 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0614 - mean_absolute_error: 0.0614\n",
      "Epoch 00015: val_loss did not improve from 0.02725\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0614 - mean_absolute_error: 0.0614 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0634 - mean_absolute_error: 0.0634\n",
      "Epoch 00016: val_loss improved from 0.02725 to 0.02583, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0634 - mean_absolute_error: 0.0634 - val_loss: 0.0258 - val_mean_absolute_error: 0.0258\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0621 - mean_absolute_error: 0.0621\n",
      "Epoch 00017: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0621 - mean_absolute_error: 0.0621 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0618 - mean_absolute_error: 0.0618\n",
      "Epoch 00018: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0618 - mean_absolute_error: 0.0618 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0604 - mean_absolute_error: 0.0604\n",
      "Epoch 00019: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0604 - mean_absolute_error: 0.0604 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0587 - mean_absolute_error: 0.0587\n",
      "Epoch 00020: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0587 - mean_absolute_error: 0.0587 - val_loss: 0.0286 - val_mean_absolute_error: 0.0286\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0594 - mean_absolute_error: 0.0594\n",
      "Epoch 00021: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0594 - mean_absolute_error: 0.0594 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0600 - mean_absolute_error: 0.0600\n",
      "Epoch 00022: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0600 - mean_absolute_error: 0.0600 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0581 - mean_absolute_error: 0.0581\n",
      "Epoch 00023: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0581 - mean_absolute_error: 0.0581 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_absolute_error: 0.0548\n",
      "Epoch 00024: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.0550\n",
      "Epoch 00025: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0550 - mean_absolute_error: 0.0550 - val_loss: 0.0280 - val_mean_absolute_error: 0.0280\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0546 - mean_absolute_error: 0.0546\n",
      "Epoch 00026: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0546 - mean_absolute_error: 0.0546 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_absolute_error: 0.0548\n",
      "Epoch 00027: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0531 - mean_absolute_error: 0.0531\n",
      "Epoch 00028: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0531 - mean_absolute_error: 0.0531 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0533 - mean_absolute_error: 0.0533\n",
      "Epoch 00029: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0533 - mean_absolute_error: 0.0533 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0556 - mean_absolute_error: 0.0556\n",
      "Epoch 00030: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0556 - mean_absolute_error: 0.0556 - val_loss: 0.0284 - val_mean_absolute_error: 0.0284\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0536 - mean_absolute_error: 0.0536\n",
      "Epoch 00031: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0536 - mean_absolute_error: 0.0536 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0544 - mean_absolute_error: 0.0544\n",
      "Epoch 00032: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0544 - mean_absolute_error: 0.0544 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0525 - mean_absolute_error: 0.0525\n",
      "Epoch 00033: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0525 - mean_absolute_error: 0.0525 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00034: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_absolute_error: 0.0530\n",
      "Epoch 00035: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0530 - mean_absolute_error: 0.0530 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0523 - mean_absolute_error: 0.0523\n",
      "Epoch 00036: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0523 - mean_absolute_error: 0.0523 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0487 - mean_absolute_error: 0.0487\n",
      "Epoch 00037: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0487 - mean_absolute_error: 0.0487 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0504 - mean_absolute_error: 0.0504\n",
      "Epoch 00038: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0504 - mean_absolute_error: 0.0504 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0518 - mean_absolute_error: 0.0518\n",
      "Epoch 00039: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0518 - mean_absolute_error: 0.0518 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.0517\n",
      "Epoch 00040: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0500 - mean_absolute_error: 0.0500\n",
      "Epoch 00041: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0500 - mean_absolute_error: 0.0500 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.0494\n",
      "Epoch 00042: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0494 - mean_absolute_error: 0.0494 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0508 - mean_absolute_error: 0.0508\n",
      "Epoch 00043: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0481 - mean_absolute_error: 0.0481\n",
      "Epoch 00044: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0481 - mean_absolute_error: 0.0481 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.0485\n",
      "Epoch 00045: val_loss did not improve from 0.02583\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0485 - mean_absolute_error: 0.0485 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_absolute_error: 0.0471\n",
      "Epoch 00046: val_loss improved from 0.02583 to 0.02573, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0471 - mean_absolute_error: 0.0471 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0502 - mean_absolute_error: 0.0502\n",
      "Epoch 00047: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0502 - mean_absolute_error: 0.0502 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.0466\n",
      "Epoch 00048: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0466 - mean_absolute_error: 0.0466 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0503 - mean_absolute_error: 0.0503\n",
      "Epoch 00049: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0503 - mean_absolute_error: 0.0503 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0488 - mean_absolute_error: 0.0488\n",
      "Epoch 00050: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0488 - mean_absolute_error: 0.0488 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0484 - mean_absolute_error: 0.0484\n",
      "Epoch 00051: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0484 - mean_absolute_error: 0.0484 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0484 - mean_absolute_error: 0.0484\n",
      "Epoch 00052: val_loss did not improve from 0.02573\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0484 - mean_absolute_error: 0.0484 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_absolute_error: 0.0493\n",
      "Epoch 00053: val_loss improved from 0.02573 to 0.02546, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_4.h5\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0493 - mean_absolute_error: 0.0493 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.0497\n",
      "Epoch 00054: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0497 - mean_absolute_error: 0.0497 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_absolute_error: 0.0490\n",
      "Epoch 00055: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0490 - mean_absolute_error: 0.0490 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0505 - mean_absolute_error: 0.0505\n",
      "Epoch 00056: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0505 - mean_absolute_error: 0.0505 - val_loss: 0.0280 - val_mean_absolute_error: 0.0280\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0510 - mean_absolute_error: 0.0510\n",
      "Epoch 00057: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0510 - mean_absolute_error: 0.0510 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.0458\n",
      "Epoch 00058: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_absolute_error: 0.0470\n",
      "Epoch 00059: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0470 - mean_absolute_error: 0.0470 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0461 - mean_absolute_error: 0.0461\n",
      "Epoch 00060: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0461 - mean_absolute_error: 0.0461 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0480 - mean_absolute_error: 0.0480\n",
      "Epoch 00061: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0480 - mean_absolute_error: 0.0480 - val_loss: 0.0275 - val_mean_absolute_error: 0.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0460 - mean_absolute_error: 0.0460\n",
      "Epoch 00062: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0460 - mean_absolute_error: 0.0460 - val_loss: 0.0284 - val_mean_absolute_error: 0.0284\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_absolute_error: 0.0471\n",
      "Epoch 00063: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0471 - mean_absolute_error: 0.0471 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0473 - mean_absolute_error: 0.0473\n",
      "Epoch 00064: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0473 - mean_absolute_error: 0.0473 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0480 - mean_absolute_error: 0.0480\n",
      "Epoch 00065: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0480 - mean_absolute_error: 0.0480 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0492 - mean_absolute_error: 0.0492\n",
      "Epoch 00066: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0492 - mean_absolute_error: 0.0492 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0492 - mean_absolute_error: 0.0492\n",
      "Epoch 00067: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0492 - mean_absolute_error: 0.0492 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.0459\n",
      "Epoch 00068: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0459 - mean_absolute_error: 0.0459 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.0458\n",
      "Epoch 00069: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.0479\n",
      "Epoch 00070: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0479 - mean_absolute_error: 0.0479 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.0466\n",
      "Epoch 00071: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0466 - mean_absolute_error: 0.0466 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.0479\n",
      "Epoch 00072: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0479 - mean_absolute_error: 0.0479 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0451 - mean_absolute_error: 0.0451\n",
      "Epoch 00073: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0451 - mean_absolute_error: 0.0451 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - mean_absolute_error: 0.0441\n",
      "Epoch 00074: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0496 - mean_absolute_error: 0.0496\n",
      "Epoch 00075: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0496 - mean_absolute_error: 0.0496 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.0450\n",
      "Epoch 00076: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0450 - mean_absolute_error: 0.0450 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_absolute_error: 0.0446\n",
      "Epoch 00077: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0446 - mean_absolute_error: 0.0446 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.0438\n",
      "Epoch 00078: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0438 - mean_absolute_error: 0.0438 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0463 - mean_absolute_error: 0.0463\n",
      "Epoch 00079: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0463 - mean_absolute_error: 0.0463 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0461 - mean_absolute_error: 0.0461\n",
      "Epoch 00080: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0461 - mean_absolute_error: 0.0461 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_absolute_error: 0.0464\n",
      "Epoch 00081: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0464 - mean_absolute_error: 0.0464 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.0452\n",
      "Epoch 00082: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0452 - mean_absolute_error: 0.0452 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.0465\n",
      "Epoch 00083: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0465 - mean_absolute_error: 0.0465 - val_loss: 0.0286 - val_mean_absolute_error: 0.0286\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_absolute_error: 0.0474\n",
      "Epoch 00084: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0474 - mean_absolute_error: 0.0474 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.0452\n",
      "Epoch 00085: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0452 - mean_absolute_error: 0.0452 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0443 - mean_absolute_error: 0.0443\n",
      "Epoch 00086: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0443 - mean_absolute_error: 0.0443 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0453 - mean_absolute_error: 0.0453\n",
      "Epoch 00087: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0453 - mean_absolute_error: 0.0453 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.0459\n",
      "Epoch 00088: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0459 - mean_absolute_error: 0.0459 - val_loss: 0.0258 - val_mean_absolute_error: 0.0258\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_absolute_error: 0.0464\n",
      "Epoch 00089: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0464 - mean_absolute_error: 0.0464 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0435 - mean_absolute_error: 0.0435\n",
      "Epoch 00090: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.0456\n",
      "Epoch 00091: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0456 - mean_absolute_error: 0.0456 - val_loss: 0.0259 - val_mean_absolute_error: 0.0259\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.0452\n",
      "Epoch 00092: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0452 - mean_absolute_error: 0.0452 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.0458\n",
      "Epoch 00093: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0455 - mean_absolute_error: 0.0455\n",
      "Epoch 00094: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0455 - mean_absolute_error: 0.0455 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.0465\n",
      "Epoch 00095: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0465 - mean_absolute_error: 0.0465 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - mean_absolute_error: 0.0441\n",
      "Epoch 00096: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0475 - mean_absolute_error: 0.0475\n",
      "Epoch 00097: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0475 - mean_absolute_error: 0.0475 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_absolute_error: 0.0470\n",
      "Epoch 00098: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0470 - mean_absolute_error: 0.0470 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0461 - mean_absolute_error: 0.0461\n",
      "Epoch 00099: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0461 - mean_absolute_error: 0.0461 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0468 - mean_absolute_error: 0.0468\n",
      "Epoch 00100: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0468 - mean_absolute_error: 0.0468 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0448 - mean_absolute_error: 0.0448\n",
      "Epoch 00101: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0448 - mean_absolute_error: 0.0448 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.0458\n",
      "Epoch 00102: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.0456\n",
      "Epoch 00103: val_loss did not improve from 0.02546\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0456 - mean_absolute_error: 0.0456 - val_loss: 0.0286 - val_mean_absolute_error: 0.0286\n",
      "Epoch 00103: early stopping\n",
      "Model for  5  angles\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1731 - mean_absolute_error: 0.1731\n",
      "Epoch 00001: val_loss improved from inf to 0.13407, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.1731 - mean_absolute_error: 0.1731 - val_loss: 0.1341 - val_mean_absolute_error: 0.1341\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1351 - mean_absolute_error: 0.1351\n",
      "Epoch 00002: val_loss improved from 0.13407 to 0.10239, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.1351 - mean_absolute_error: 0.1351 - val_loss: 0.1024 - val_mean_absolute_error: 0.1024\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.1212\n",
      "Epoch 00003: val_loss improved from 0.10239 to 0.08593, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.0859 - val_mean_absolute_error: 0.0859\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1099 - mean_absolute_error: 0.1099\n",
      "Epoch 00004: val_loss improved from 0.08593 to 0.07369, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1099 - mean_absolute_error: 0.1099 - val_loss: 0.0737 - val_mean_absolute_error: 0.0737\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1013 - mean_absolute_error: 0.1013\n",
      "Epoch 00005: val_loss improved from 0.07369 to 0.06876, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.1013 - mean_absolute_error: 0.1013 - val_loss: 0.0688 - val_mean_absolute_error: 0.0688\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 00006: val_loss improved from 0.06876 to 0.06294, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 00007: val_loss did not improve from 0.06294\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0867 - mean_absolute_error: 0.0867\n",
      "Epoch 00008: val_loss improved from 0.06294 to 0.06191, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 289ms/step - loss: 0.0867 - mean_absolute_error: 0.0867 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0879 - mean_absolute_error: 0.0879\n",
      "Epoch 00009: val_loss improved from 0.06191 to 0.06088, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0879 - mean_absolute_error: 0.0879 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0857 - mean_absolute_error: 0.0857\n",
      "Epoch 00010: val_loss improved from 0.06088 to 0.05801, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.0857 - mean_absolute_error: 0.0857 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0829 - mean_absolute_error: 0.0829\n",
      "Epoch 00011: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0641 - val_mean_absolute_error: 0.0641\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.0805\n",
      "Epoch 00012: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0805 - mean_absolute_error: 0.0805 - val_loss: 0.0659 - val_mean_absolute_error: 0.0659\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0779 - mean_absolute_error: 0.0779\n",
      "Epoch 00013: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0831 - mean_absolute_error: 0.0831\n",
      "Epoch 00014: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0821 - mean_absolute_error: 0.0821\n",
      "Epoch 00015: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0601 - val_mean_absolute_error: 0.0601\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0786 - mean_absolute_error: 0.0786\n",
      "Epoch 00016: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0786 - mean_absolute_error: 0.0786 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0771 - mean_absolute_error: 0.0771\n",
      "Epoch 00017: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0771 - mean_absolute_error: 0.0771 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0843 - mean_absolute_error: 0.0843\n",
      "Epoch 00018: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0638 - val_mean_absolute_error: 0.0638\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0736 - mean_absolute_error: 0.0736\n",
      "Epoch 00019: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0773 - mean_absolute_error: 0.0773\n",
      "Epoch 00020: val_loss did not improve from 0.05801\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0773 - mean_absolute_error: 0.0773 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0738 - mean_absolute_error: 0.0738\n",
      "Epoch 00021: val_loss improved from 0.05801 to 0.05727, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0573 - val_mean_absolute_error: 0.0573\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0753 - mean_absolute_error: 0.0753\n",
      "Epoch 00022: val_loss did not improve from 0.05727\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0773 - mean_absolute_error: 0.0773\n",
      "Epoch 00023: val_loss did not improve from 0.05727\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0773 - mean_absolute_error: 0.0773 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0796 - mean_absolute_error: 0.0796\n",
      "Epoch 00024: val_loss improved from 0.05727 to 0.05633, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0773 - mean_absolute_error: 0.0773\n",
      "Epoch 00025: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0773 - mean_absolute_error: 0.0773 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0783 - mean_absolute_error: 0.0783\n",
      "Epoch 00026: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0783 - mean_absolute_error: 0.0783 - val_loss: 0.0652 - val_mean_absolute_error: 0.0652\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.0720\n",
      "Epoch 00027: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0633 - val_mean_absolute_error: 0.0633\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0752 - mean_absolute_error: 0.0752\n",
      "Epoch 00028: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.0721\n",
      "Epoch 00029: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0615 - val_mean_absolute_error: 0.0615\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.0720\n",
      "Epoch 00030: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0785 - mean_absolute_error: 0.0785\n",
      "Epoch 00031: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0785 - mean_absolute_error: 0.0785 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0713 - mean_absolute_error: 0.0713\n",
      "Epoch 00032: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0713 - mean_absolute_error: 0.0713 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0736 - mean_absolute_error: 0.0736\n",
      "Epoch 00033: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0742 - mean_absolute_error: 0.0742\n",
      "Epoch 00034: val_loss did not improve from 0.05633\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.0725\n",
      "Epoch 00035: val_loss improved from 0.05633 to 0.05628, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0749 - mean_absolute_error: 0.0749\n",
      "Epoch 00036: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0749 - mean_absolute_error: 0.0749 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0766 - mean_absolute_error: 0.0766\n",
      "Epoch 00037: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0766 - mean_absolute_error: 0.0766 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0752 - mean_absolute_error: 0.0752\n",
      "Epoch 00038: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.0727\n",
      "Epoch 00039: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0614 - val_mean_absolute_error: 0.0614\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.0679\n",
      "Epoch 00040: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0679 - mean_absolute_error: 0.0679 - val_loss: 0.0593 - val_mean_absolute_error: 0.0593\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.0684\n",
      "Epoch 00041: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0644 - val_mean_absolute_error: 0.0644\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0723 - mean_absolute_error: 0.0723\n",
      "Epoch 00042: val_loss did not improve from 0.05628\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.0685\n",
      "Epoch 00043: val_loss improved from 0.05628 to 0.05361, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_5.h5\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.0701\n",
      "Epoch 00044: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0701 - mean_absolute_error: 0.0701 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.0701\n",
      "Epoch 00045: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0701 - mean_absolute_error: 0.0701 - val_loss: 0.0610 - val_mean_absolute_error: 0.0610\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.0721\n",
      "Epoch 00046: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0627 - val_mean_absolute_error: 0.0627\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0688 - mean_absolute_error: 0.0688\n",
      "Epoch 00047: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0664 - mean_absolute_error: 0.0664\n",
      "Epoch 00048: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0664 - mean_absolute_error: 0.0664 - val_loss: 0.0578 - val_mean_absolute_error: 0.0578\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.0668\n",
      "Epoch 00049: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0668 - mean_absolute_error: 0.0668 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.0711\n",
      "Epoch 00050: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0711 - mean_absolute_error: 0.0711 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0716 - mean_absolute_error: 0.0716\n",
      "Epoch 00051: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0716 - mean_absolute_error: 0.0716 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0695 - mean_absolute_error: 0.0695\n",
      "Epoch 00052: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0695 - mean_absolute_error: 0.0695 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.0671\n",
      "Epoch 00053: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.0690\n",
      "Epoch 00054: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0706 - mean_absolute_error: 0.0706\n",
      "Epoch 00055: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0706 - mean_absolute_error: 0.0706 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0653 - mean_absolute_error: 0.0653\n",
      "Epoch 00056: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0653 - mean_absolute_error: 0.0653 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.0690\n",
      "Epoch 00057: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.0683\n",
      "Epoch 00058: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0683 - mean_absolute_error: 0.0683 - val_loss: 0.0541 - val_mean_absolute_error: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.0694\n",
      "Epoch 00059: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0694 - mean_absolute_error: 0.0694 - val_loss: 0.0649 - val_mean_absolute_error: 0.0649\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.0692\n",
      "Epoch 00060: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0692 - mean_absolute_error: 0.0692 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.0702\n",
      "Epoch 00061: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0702 - mean_absolute_error: 0.0702 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0687 - mean_absolute_error: 0.0687\n",
      "Epoch 00062: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0573 - val_mean_absolute_error: 0.0573\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0661 - mean_absolute_error: 0.0661\n",
      "Epoch 00063: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0661 - mean_absolute_error: 0.0661 - val_loss: 0.0576 - val_mean_absolute_error: 0.0576\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.0659\n",
      "Epoch 00064: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0659 - mean_absolute_error: 0.0659 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.0659\n",
      "Epoch 00065: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0659 - mean_absolute_error: 0.0659 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.0674\n",
      "Epoch 00066: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.0678\n",
      "Epoch 00067: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0678 - mean_absolute_error: 0.0678 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.0660\n",
      "Epoch 00068: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0660 - mean_absolute_error: 0.0660 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0646 - mean_absolute_error: 0.0646\n",
      "Epoch 00069: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0646 - mean_absolute_error: 0.0646 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0667 - mean_absolute_error: 0.0667\n",
      "Epoch 00070: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0667 - mean_absolute_error: 0.0667 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.0675\n",
      "Epoch 00071: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0675 - mean_absolute_error: 0.0675 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.0624\n",
      "Epoch 00072: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0624 - mean_absolute_error: 0.0624 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0658 - mean_absolute_error: 0.0658\n",
      "Epoch 00073: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0658 - mean_absolute_error: 0.0658 - val_loss: 0.0607 - val_mean_absolute_error: 0.0607\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mean_absolute_error: 0.0697\n",
      "Epoch 00074: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0697 - mean_absolute_error: 0.0697 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0681 - mean_absolute_error: 0.0681\n",
      "Epoch 00075: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0681 - mean_absolute_error: 0.0681 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0627 - mean_absolute_error: 0.0627\n",
      "Epoch 00076: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0627 - mean_absolute_error: 0.0627 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0695 - mean_absolute_error: 0.0695\n",
      "Epoch 00077: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0695 - mean_absolute_error: 0.0695 - val_loss: 0.0585 - val_mean_absolute_error: 0.0585\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.0674\n",
      "Epoch 00078: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0596 - val_mean_absolute_error: 0.0596\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0632 - mean_absolute_error: 0.0632\n",
      "Epoch 00079: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0632 - mean_absolute_error: 0.0632 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.0654\n",
      "Epoch 00080: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0654 - mean_absolute_error: 0.0654 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0655 - mean_absolute_error: 0.0655\n",
      "Epoch 00081: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0655 - mean_absolute_error: 0.0655 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0625 - mean_absolute_error: 0.0625\n",
      "Epoch 00082: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0625 - mean_absolute_error: 0.0625 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0652 - mean_absolute_error: 0.0652\n",
      "Epoch 00083: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0652 - mean_absolute_error: 0.0652 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.0674\n",
      "Epoch 00084: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0629 - val_mean_absolute_error: 0.0629\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.0669\n",
      "Epoch 00085: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0643 - mean_absolute_error: 0.0643\n",
      "Epoch 00086: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0643 - mean_absolute_error: 0.0643 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0627 - mean_absolute_error: 0.0627\n",
      "Epoch 00087: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0627 - mean_absolute_error: 0.0627 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mean_absolute_error: 0.0639\n",
      "Epoch 00088: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0639 - mean_absolute_error: 0.0639 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0631 - mean_absolute_error: 0.0631\n",
      "Epoch 00089: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0631 - mean_absolute_error: 0.0631 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0646 - mean_absolute_error: 0.0646\n",
      "Epoch 00090: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0646 - mean_absolute_error: 0.0646 - val_loss: 0.0557 - val_mean_absolute_error: 0.0557\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0615 - mean_absolute_error: 0.0615\n",
      "Epoch 00091: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0615 - mean_absolute_error: 0.0615 - val_loss: 0.0596 - val_mean_absolute_error: 0.0596\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0599 - mean_absolute_error: 0.0599\n",
      "Epoch 00092: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0599 - mean_absolute_error: 0.0599 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0640 - mean_absolute_error: 0.0640\n",
      "Epoch 00093: val_loss did not improve from 0.05361\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0640 - mean_absolute_error: 0.0640 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "Epoch 00093: early stopping\n",
      "Model for  6  angles\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1980 - mean_absolute_error: 0.1980\n",
      "Epoch 00001: val_loss improved from inf to 0.12455, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.1980 - mean_absolute_error: 0.1980 - val_loss: 0.1246 - val_mean_absolute_error: 0.1246\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1745 - mean_absolute_error: 0.1745\n",
      "Epoch 00002: val_loss improved from 0.12455 to 0.09072, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.1745 - mean_absolute_error: 0.1745 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1545 - mean_absolute_error: 0.1545\n",
      "Epoch 00003: val_loss improved from 0.09072 to 0.08304, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1545 - mean_absolute_error: 0.1545 - val_loss: 0.0830 - val_mean_absolute_error: 0.0830\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1369 - mean_absolute_error: 0.1369\n",
      "Epoch 00004: val_loss improved from 0.08304 to 0.07839, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1369 - mean_absolute_error: 0.1369 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1337 - mean_absolute_error: 0.1337\n",
      "Epoch 00005: val_loss improved from 0.07839 to 0.07037, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.1180\n",
      "Epoch 00006: val_loss improved from 0.07037 to 0.06875, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.1180 - mean_absolute_error: 0.1180 - val_loss: 0.0688 - val_mean_absolute_error: 0.0688\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.1183\n",
      "Epoch 00007: val_loss improved from 0.06875 to 0.06851, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.1183 - mean_absolute_error: 0.1183 - val_loss: 0.0685 - val_mean_absolute_error: 0.0685\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1126 - mean_absolute_error: 0.1126\n",
      "Epoch 00008: val_loss improved from 0.06851 to 0.06578, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1126 - mean_absolute_error: 0.1126 - val_loss: 0.0658 - val_mean_absolute_error: 0.0658\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1042 - mean_absolute_error: 0.1042\n",
      "Epoch 00009: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.1042 - mean_absolute_error: 0.1042 - val_loss: 0.0691 - val_mean_absolute_error: 0.0691\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1105 - mean_absolute_error: 0.1105\n",
      "Epoch 00010: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.1105 - mean_absolute_error: 0.1105 - val_loss: 0.0664 - val_mean_absolute_error: 0.0664\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1074 - mean_absolute_error: 0.1074\n",
      "Epoch 00011: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.1074 - mean_absolute_error: 0.1074 - val_loss: 0.0681 - val_mean_absolute_error: 0.0681\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1042 - mean_absolute_error: 0.1042\n",
      "Epoch 00012: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.1042 - mean_absolute_error: 0.1042 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1096 - mean_absolute_error: 0.1096\n",
      "Epoch 00013: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.1096 - mean_absolute_error: 0.1096 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0993 - mean_absolute_error: 0.0993\n",
      "Epoch 00014: val_loss did not improve from 0.06578\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0993 - mean_absolute_error: 0.0993 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1024 - mean_absolute_error: 0.1024\n",
      "Epoch 00015: val_loss improved from 0.06578 to 0.06073, saving model to /home/renat_sergazinov/python-git-workspace/PhotoForceReconML/models/small/400/InceptionResNetV2_mags_6.h5\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.1024 - mean_absolute_error: 0.1024 - val_loss: 0.0607 - val_mean_absolute_error: 0.0607\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0993 - mean_absolute_error: 0.0993\n",
      "Epoch 00016: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0993 - mean_absolute_error: 0.0993 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1012 - mean_absolute_error: 0.1012\n",
      "Epoch 00017: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.1012 - mean_absolute_error: 0.1012 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1005 - mean_absolute_error: 0.1005\n",
      "Epoch 00018: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.1005 - mean_absolute_error: 0.1005 - val_loss: 0.0725 - val_mean_absolute_error: 0.0725\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0938 - mean_absolute_error: 0.0938\n",
      "Epoch 00019: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0976 - mean_absolute_error: 0.0976\n",
      "Epoch 00020: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0976 - mean_absolute_error: 0.0976 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0952 - mean_absolute_error: 0.0952\n",
      "Epoch 00021: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0952 - mean_absolute_error: 0.0952 - val_loss: 0.0768 - val_mean_absolute_error: 0.0768\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00022: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0665 - val_mean_absolute_error: 0.0665\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.0934\n",
      "Epoch 00023: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0997 - mean_absolute_error: 0.0997\n",
      "Epoch 00024: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0997 - mean_absolute_error: 0.0997 - val_loss: 0.0688 - val_mean_absolute_error: 0.0688\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.0939\n",
      "Epoch 00025: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0939 - mean_absolute_error: 0.0939 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 00026: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 00027: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.0658 - val_mean_absolute_error: 0.0658\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.0949\n",
      "Epoch 00028: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0678 - val_mean_absolute_error: 0.0678\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0946 - mean_absolute_error: 0.0946\n",
      "Epoch 00029: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0946 - mean_absolute_error: 0.0946 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00030: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0974 - mean_absolute_error: 0.0974\n",
      "Epoch 00031: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0974 - mean_absolute_error: 0.0974 - val_loss: 0.0663 - val_mean_absolute_error: 0.0663\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0935 - mean_absolute_error: 0.0935\n",
      "Epoch 00032: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0935 - mean_absolute_error: 0.0935 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.0942\n",
      "Epoch 00033: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.0763 - val_mean_absolute_error: 0.0763\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0975 - mean_absolute_error: 0.0975\n",
      "Epoch 00034: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0975 - mean_absolute_error: 0.0975 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.0915\n",
      "Epoch 00035: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 00036: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.0695 - val_mean_absolute_error: 0.0695\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.0932\n",
      "Epoch 00037: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.0693 - val_mean_absolute_error: 0.0693\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0912 - mean_absolute_error: 0.0912\n",
      "Epoch 00038: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 00039: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.0663 - val_mean_absolute_error: 0.0663\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.0908\n",
      "Epoch 00040: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0908 - mean_absolute_error: 0.0908 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0922 - mean_absolute_error: 0.0922\n",
      "Epoch 00041: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.0695 - val_mean_absolute_error: 0.0695\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0872 - mean_absolute_error: 0.0872\n",
      "Epoch 00042: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0872 - mean_absolute_error: 0.0872 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0964 - mean_absolute_error: 0.0964\n",
      "Epoch 00043: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.0746 - val_mean_absolute_error: 0.0746\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_error: 0.0893\n",
      "Epoch 00044: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0872 - mean_absolute_error: 0.0872\n",
      "Epoch 00045: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0872 - mean_absolute_error: 0.0872 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0914 - mean_absolute_error: 0.0914\n",
      "Epoch 00046: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.0757 - val_mean_absolute_error: 0.0757\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 00047: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 00048: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.0640 - val_mean_absolute_error: 0.0640\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0903 - mean_absolute_error: 0.0903\n",
      "Epoch 00049: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0903 - mean_absolute_error: 0.0903 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0883 - mean_absolute_error: 0.0883\n",
      "Epoch 00050: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0883 - mean_absolute_error: 0.0883 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0884 - mean_absolute_error: 0.0884\n",
      "Epoch 00051: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0884 - mean_absolute_error: 0.0884 - val_loss: 0.0736 - val_mean_absolute_error: 0.0736\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 00052: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0911 - mean_absolute_error: 0.0911\n",
      "Epoch 00053: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.0649 - val_mean_absolute_error: 0.0649\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.0908\n",
      "Epoch 00054: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0908 - mean_absolute_error: 0.0908 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0845 - mean_absolute_error: 0.0845\n",
      "Epoch 00055: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0903 - mean_absolute_error: 0.0903\n",
      "Epoch 00056: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0903 - mean_absolute_error: 0.0903 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0883 - mean_absolute_error: 0.0883\n",
      "Epoch 00057: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0883 - mean_absolute_error: 0.0883 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0856 - mean_absolute_error: 0.0856\n",
      "Epoch 00058: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0856 - mean_absolute_error: 0.0856 - val_loss: 0.0685 - val_mean_absolute_error: 0.0685\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0918 - mean_absolute_error: 0.0918\n",
      "Epoch 00059: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0918 - mean_absolute_error: 0.0918 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0876 - mean_absolute_error: 0.0876\n",
      "Epoch 00060: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0876 - mean_absolute_error: 0.0876 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0847 - mean_absolute_error: 0.0847\n",
      "Epoch 00061: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0856 - mean_absolute_error: 0.0856\n",
      "Epoch 00062: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0856 - mean_absolute_error: 0.0856 - val_loss: 0.0684 - val_mean_absolute_error: 0.0684\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0897 - mean_absolute_error: 0.0897\n",
      "Epoch 00063: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.0694 - val_mean_absolute_error: 0.0694\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.0835\n",
      "Epoch 00064: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0894 - mean_absolute_error: 0.0894\n",
      "Epoch 00065: val_loss did not improve from 0.06073\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0894 - mean_absolute_error: 0.0894 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
      "Epoch 00065: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "history = {}\n",
    "\n",
    "for k in range(5):\n",
    "    i = k + 2\n",
    "    print('Model for ', i, ' angles')\n",
    "    history[i] = models_m[i].fit(training_generator[i],\n",
    "                            validation_data = validation_generator[i],\n",
    "                            epochs = epochs,\n",
    "                            steps_per_epoch = len(training_generator[i]),\n",
    "                            validation_steps = len(validation_generator[i]),\n",
    "                            callbacks=[es, mc[i]]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 15))\n",
    "for i in range(5):\n",
    "    fig.add_subplot(3, 2, i+1)\n",
    "    plt.plot(history[i+2].history['loss'])\n",
    "    plt.plot(history[i+2].history['val_loss'])\n",
    "    plt.title('Model loss '+str(i+2))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
